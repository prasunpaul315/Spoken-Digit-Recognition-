{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwoTWIysaNmc"
   },
   "source": [
    "# <font color='red'> Spoken Digit Recognition</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPO3mjDDaNmf"
   },
   "source": [
    "\n",
    "In this notebook, You will do Spoken Digit Recognition. \n",
    "\n",
    "Input - speech signal, output - digit number\n",
    "\n",
    "\n",
    "\n",
    "It contains  \n",
    "\n",
    "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
    "2. Training the LSTM with RAW data\n",
    "3. Converting to spectrogram and Training the LSTM network\n",
    "4. Creating the augmented data and doing step 2 and 3 again.  \n",
    "\n",
    "<font size=5>Instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. Please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_qGuPcj-aNmh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "##if you need any imports you can do that here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdhFzGK1aNmo"
   },
   "source": [
    "We shared recordings.zip, please unzip those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HDBcl_PUaNmp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the all file names in the recordings folder given by us\n",
    "#(if you get entire path, it is very useful in future)\n",
    "#save those files names as list in \"all_files\"\n",
    "\n",
    "all_files = os.listdir(r\"recordings\")\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NYYpfqoaNmv"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2oJSOmYBaNmx",
    "outputId": "d4509e7d-1cb6-4e7f-e469-ef40314a8510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_files():\n",
    "    temp = len(all_files)==2000\n",
    "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
    "    temp = temp and temp1\n",
    "    return temp\n",
    "grader_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZbhCvvRPPMw"
   },
   "source": [
    "## Exploring the sound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ilJsqdhhPMed"
   },
   "outputs": [],
   "source": [
    "#It is a good programming practise to explore the dataset that you are dealing with. This dataset is unique in itself because it has sounds as input\n",
    "#https://colab.research.google.com/github/Tyler-Hilbert/AudioProcessingInPythonWorkshop/blob/master/AudioProcessingInPython.ipynb\n",
    "#visualize the data and write code to play 2-3 sound samples in the notebook for better understanding.\n",
    "#please go through the following reference video https://www.youtube.com/watch?v=37zCgCdV468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7_jackson_7.wav',\n",
       " '8_yweweler_23.wav',\n",
       " '1_yweweler_1.wav',\n",
       " '0_yweweler_3.wav',\n",
       " '6_jackson_44.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bX_umjikPy5Y"
   },
   "outputs": [],
   "source": [
    "df_audio = pd.DataFrame()\n",
    "\n",
    "def dataframe(root_dir):\n",
    "    path = []\n",
    "    label = []\n",
    "    for i in range(len(all_files)):\n",
    "        path.append(root_dir+'/'+all_files[i])\n",
    "        label.append(all_files[i][0])\n",
    "        \n",
    "    df_audio['path'] = path\n",
    "    df_audio['label'] = label\n",
    "        \n",
    "    return df_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7Wx5tOjSPX2Y"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recordings/7_jackson_7.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recordings/8_yweweler_23.wav</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recordings/1_yweweler_1.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recordings/0_yweweler_3.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recordings/6_jackson_44.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path label\n",
       "0    recordings/7_jackson_7.wav     7\n",
       "1  recordings/8_yweweler_23.wav     8\n",
       "2   recordings/1_yweweler_1.wav     1\n",
       "3   recordings/0_yweweler_3.wav     0\n",
       "4   recordings/6_jackson_44.wav     6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = 'recordings'\n",
    "df_audio = dataframe(root_dir)\n",
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA0nAtjbQLmu"
   },
   "source": [
    "## Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKpYJ_LaNnD"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7Q8r_T8-aNnE",
    "outputId": "849e3f3e-e77c-492c-ba29-77508e74fc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_df():\n",
    "    flag_shape = df_audio.shape==(2000,2)\n",
    "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
    "    list_values = list(df_audio.label.value_counts())\n",
    "    flag_label = len(list_values)==10\n",
    "    flag_label2 = all([i==200 for i in list_values])\n",
    "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
    "    return final_flag\n",
    "grader_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [],
   "source": [
    "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
    "#use stratify sampling\n",
    "#use random state of 45\n",
    "#use test size of 30%\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_audio['path']\n",
    "y = df_audio['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3,random_state=45,stratify=y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (1400,) (1400,)\n",
      "test shape:   (600,) (600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", X_train.shape, y_train.shape)\n",
    "print(\"test shape:  \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPK3sbzUaNnW"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "chZzntKUaNnX",
    "outputId": "e2949c8b-2f00-434f-8403-56b577faf04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_split():\n",
    "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
    "    values_ytrain = list(y_train.value_counts())\n",
    "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
    "    values_ytest = list(y_test.value_counts())\n",
    "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
    "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
    "    return final_flag\n",
    "grader_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rx97f8GGaNnh"
   },
   "outputs": [],
   "source": [
    "#use load_wav function that was written above to get every wave. \n",
    "#save it in X_train_processed and X_test_processed\n",
    "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1400/1400 [00:13<00:00, 106.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tr = X_train.values\n",
    "\n",
    "train_raw_data = []\n",
    "train_duration = []\n",
    "\n",
    "for i in tqdm(range(len(X_tr))):\n",
    "    samples, duration = load_wav(X_tr[i])\n",
    "    train_raw_data.append(samples)\n",
    "    train_duration.append(duration)\n",
    "    \n",
    "X_train_processed = pd.DataFrame()\n",
    "X_train_processed['raw_data'] = train_raw_data\n",
    "X_train_processed['duration'] = train_duration\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00087281835, 0.0004117749, -2.936911e-05, -...</td>\n",
       "      <td>0.327755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00038002394, -0.00019715699, 0.00010046658...</td>\n",
       "      <td>0.427029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0002015104, -8.0844686e-05, -3.0828054e-05...</td>\n",
       "      <td>0.222630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0012677191, 0.001223072, 0.0006890931, -0.0...</td>\n",
       "      <td>0.477143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.007789636, -0.009217891, -0.008847748, -0....</td>\n",
       "      <td>0.426168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [0.00087281835, 0.0004117749, -2.936911e-05, -...  0.327755\n",
       "1  [-0.00038002394, -0.00019715699, 0.00010046658...  0.427029\n",
       "2  [-0.0002015104, -8.0844686e-05, -3.0828054e-05...  0.222630\n",
       "3  [0.0012677191, 0.001223072, 0.0006890931, -0.0...  0.477143\n",
       "4  [-0.007789636, -0.009217891, -0.008847748, -0....  0.426168"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 600/600 [00:05<00:00, 113.31it/s]\n"
     ]
    }
   ],
   "source": [
    "X_te = X_test.values\n",
    "\n",
    "test_raw_data = []\n",
    "test_duration = []\n",
    "\n",
    "for i in tqdm(range(len(X_te))):\n",
    "    samples, duration = load_wav(X_te[i])\n",
    "    test_raw_data.append(samples)\n",
    "    test_duration.append(duration)\n",
    "    \n",
    "X_test_processed = pd.DataFrame()\n",
    "X_test_processed['raw_data'] = test_raw_data\n",
    "X_test_processed['duration'] = test_duration\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.00018607912, -0.0002530324, -0.00028846323...</td>\n",
       "      <td>0.259138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.02292528, -0.03088903, -0.033623796, -0.03...</td>\n",
       "      <td>0.395011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.030367538, -0.026899911, -0.013228855, 0.0...</td>\n",
       "      <td>0.309887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.00011964719, -0.0019205003, -0.0052836672, ...</td>\n",
       "      <td>0.470385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.00023663024, 0.00028101765, 0.00023928868, ...</td>\n",
       "      <td>0.513152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [-0.00018607912, -0.0002530324, -0.00028846323...  0.259138\n",
       "1  [-0.02292528, -0.03088903, -0.033623796, -0.03...  0.395011\n",
       "2  [-0.030367538, -0.026899911, -0.013228855, 0.0...  0.309887\n",
       "3  [0.00011964719, -0.0019205003, -0.0052836672, ...  0.470385\n",
       "4  [0.00023663024, 0.00028101765, 0.00023928868, ...  0.513152"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for trian\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(X_train_processed['duration'])\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wE5SDRzSaNns",
    "outputId": "f2501a90-2a43-43db-f02c-1463defe2146"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for test\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(X_test_processed['duration'])\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th percentile is 0.1435374149659864\n",
      "10 th percentile is 0.2597732426303855\n",
      "20 th percentile is 0.3020408163265306\n",
      "30 th percentile is 0.3322902494331066\n",
      "40 th percentile is 0.35950113378684806\n",
      "50 th percentile is 0.389750566893424\n",
      "60 th percentile is 0.4164172335600907\n",
      "70 th percentile is 0.44825396825396824\n",
      "80 th percentile is 0.48462585034013606\n",
      "90 th percentile is 0.5599092970521542\n",
      "100 th percentile is  2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "\n",
    "for i in range(0,100,10):\n",
    "    var = X_train_processed['duration'].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} th percentile is {}\".format(int(i),var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 th percentile is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rSlVQh4CaNn2",
    "outputId": "d6970436-db83-4d01-c910-7ebe92baab41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 th percentile is 0.5599092970521542\n",
      "91 th percentile is 0.5759183673469388\n",
      "92 th percentile is 0.5851700680272108\n",
      "93 th percentile is 0.6078911564625851\n",
      "94 th percentile is 0.6210430839002268\n",
      "95 th percentile is 0.6346485260770975\n",
      "96 th percentile is 0.648390022675737\n",
      "97 th percentile is 0.6742857142857143\n",
      "98 th percentile is 0.7120181405895691\n",
      "99 th percentile is 0.8067573696145125\n",
      "100 th percentile is  2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "\n",
    "for i in range(90,100,1):\n",
    "    var = X_train_processed['duration'].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} th percentile is {}\".format(int(i),var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 th percentile is \",var[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbMb4Y0RaNoA"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "UMoyLLSAaNoF",
    "outputId": "cfb3ad33-3dc0-49e7-d078-8619b164b5db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_processed():\n",
    "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
    "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
    "    return flag_columns and flag_shape\n",
    "grader_processed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<b>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset.</b>\n",
    "\n",
    "<b>While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "</b>\n",
    "<b>Pad with Zero if length of sequence is less than 17640 else Truncate the number. </b>\n",
    "\n",
    "<b> Also create a masking vector for train and test. </b>\n",
    "\n",
    "<b> masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "B1-_r20BaNoW"
   },
   "outputs": [],
   "source": [
    "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "## save in the X_train_pad_seq, X_test_pad_seq\n",
    "## also Create masking vector X_train_mask, X_test_mask\n",
    "\n",
    "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7227\n",
      "0.3277551020408163\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_processed['raw_data'][0]))\n",
    "print(X_train_processed['duration'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 17640)\n",
      "(600, 17640)\n",
      "(1400, 17640)\n",
      "(600, 17640)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/30475558/padding-or-truncating-a-python-list\n",
    "\n",
    "def trp(l, n):\n",
    "    \"\"\" Truncate or pad a list \"\"\"\n",
    "    r = list(l[:n])\n",
    "    if(len(r) < n):\n",
    "        r.extend([0] * (n - len(r)))\n",
    "    return r\n",
    "\n",
    "X_train_pad_seq = []\n",
    "X_train_mask = []\n",
    "X_test_pad_seq = []\n",
    "X_test_mask = []\n",
    "\n",
    "for i in range(len(X_train_processed)):\n",
    "    pad_seq = trp(np.array(X_train_processed['raw_data'][i]), max_length)\n",
    "    X_train_pad_seq.append(pad_seq)\n",
    "    \n",
    "    \n",
    "for i in range(len(X_test_processed)):\n",
    "    pad_seq = trp(np.array(X_test_processed['raw_data'][i]), max_length)\n",
    "    X_test_pad_seq.append(pad_seq)\n",
    "    \n",
    "\n",
    "\n",
    "X_train_pad_seq = np.array(X_train_pad_seq)\n",
    "X_test_pad_seq = np.array(X_test_pad_seq)\n",
    "\n",
    "X_train_mask = np.where(X_train_pad_seq != 0, 1, 0)\n",
    "X_train_mask = X_train_mask.astype(bool)\n",
    "X_test_mask = np.where(X_test_pad_seq != 0, 1, 0)\n",
    "X_test_mask = X_test_mask.astype(bool)\n",
    "\n",
    "print(X_train_pad_seq.shape)\n",
    "print(X_test_pad_seq.shape)\n",
    "\n",
    "print(X_train_mask.shape)\n",
    "print(X_test_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEHMgm4DaNoe"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Th3KhplGaNof",
    "outputId": "5e783ec9-81d2-4156-9e88-efdee0ff8b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_padoutput():\n",
    "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
    "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
    "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
    "    return flag_padshape and flag_maskshape and flag_dtype\n",
    "grader_padoutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kaYQ1jaNop"
   },
   "source": [
    "### 1. Giving Raw data directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHxh3jTaNoq"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
    "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
    "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). Also check the datatype of class labels(y_values) and make sure that you convert your class labels  to integer datatype before fitting in the model.\n",
    "3. While defining your model make sure that you pass both the input layer and mask input layer as input to lstm layer as follows\n",
    "<img src='https://i.imgur.com/FvcgvbY.jpg'>\n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "\n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train[4]), type(y_test[17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    140\n",
       "1    140\n",
       "5    140\n",
       "0    140\n",
       "2    140\n",
       "8    140\n",
       "9    140\n",
       "7    140\n",
       "3    140\n",
       "4    140\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    60\n",
       "5    60\n",
       "2    60\n",
       "6    60\n",
       "9    60\n",
       "0    60\n",
       "1    60\n",
       "4    60\n",
       "8    60\n",
       "7    60\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "X8yg951AaNor"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 10:30:00.477107: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, concatenate, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,LearningRateScheduler\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "d8y1sgeVaNoy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:06:32.360235: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-09-02 10:06:32.360304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu22): /proc/driver/nvidia/version does not exist\n",
      "2022-09-02 10:06:32.372677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " seq_inp (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " mask_inp (InputLayer)          [(None, 17640)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           16896       ['seq_inp[0][0]',                \n",
      "                                                                  'mask_inp[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           4160        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           650         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,706\n",
      "Trainable params: 21,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## as discussed above, please write the architecture of the model.\n",
    "## you will have two input layers in your model (data input layer and mask input layer)\n",
    "## make sure that you have defined the data type of masking layer as bool\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "seq_inp_layer = Input(shape=(17640,1), dtype='float32',name='seq_inp')\n",
    "mask_inp_layer = Input(shape=(17640), dtype='bool',name='mask_inp')\n",
    "lstm = LSTM(64)(seq_inp_layer,mask=mask_inp_layer)\n",
    "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(lstm)\n",
    "dp1 = Dropout(0.2)(fc1)\n",
    "out_layer = Dense(10,activation='softmax')(dp1)\n",
    "\n",
    "model1 = Model(inputs=[seq_inp_layer,mask_inp_layer],outputs=out_layer)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "RPj_DGW2aNo9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model1, to_file='model1/model1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.x_test = validation_data[0]\n",
    "        self.y_test = validation_data[1]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label = np.argmax(val_predict, axis = 1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label, average='micro')\n",
    "        print(\"val_F1_score: \", val_f1)\n",
    "        \n",
    "metrics = Metrics(validation_data=([X_test_pad_seq,X_test_mask], y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:06:34.157948: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-02 10:06:34.158017: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-02 10:06:34.191964: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "tensorboard1 = TensorBoard(log_dir='model1/model1_logs'.format(time()), histogram_freq=1, write_graph=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='./model1/best_model_1.h5', save_weights_only = True, save_best_only = True, \\\n",
    "                                       mode = 'max', monitor = 'val_accuracy', verbose = 1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', patience = 1, mode = 'max', verbose = 1),\n",
    "    tf.keras.callbacks.CSVLogger('./model1/history.csv'),\n",
    "]\n",
    "\n",
    "\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.06,decay = 1e-4),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "MzpPjxvHaNpJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/22 [>.............................] - ETA: 3:40 - loss: 2.3026 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:06:45.713180: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-02 10:06:45.713235: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-02 10:06:56.415031: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-09-02 10:07:05.657513: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-02 10:07:13.363033: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06\n",
      "\n",
      "2022-09-02 10:07:16.463181: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.trace.json.gz\n",
      "2022-09-02 10:07:21.106844: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06\n",
      "\n",
      "2022-09-02 10:07:21.224181: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.memory_profile.json.gz\n",
      "2022-09-02 10:07:22.490586: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06\n",
      "Dumped tool data for xplane.pb to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model1/model1_logs/train/plugins/profile/2022_09_02_10_07_06/ubuntu22.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 2.3428 - accuracy: 0.1000 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to ./model1/best_model_1.h5\n",
      "19/19 [==============================] - 30s 2s/step\n",
      "val_F1_score:  0.10000000000000002\n",
      "22/22 [==============================] - 294s 13s/step - loss: 2.3428 - accuracy: 0.1000 - val_loss: 2.3091 - val_accuracy: 0.1000 - lr: 0.0600\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.3191 - accuracy: 0.0921\n",
      "Epoch 2: val_accuracy did not improve from 0.10000\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00599999986588955.\n",
      "19/19 [==============================] - 27s 1s/step\n",
      "val_F1_score:  0.10000000000000002\n",
      "22/22 [==============================] - 252s 12s/step - loss: 2.3191 - accuracy: 0.0921 - val_loss: 2.3069 - val_accuracy: 0.1000 - lr: 0.0600\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.3068 - accuracy: 0.1000\n",
      "Epoch 3: val_accuracy did not improve from 0.10000\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0006000000052154065.\n",
      "19/19 [==============================] - 32s 2s/step\n",
      "val_F1_score:  0.10000000000000002\n",
      "22/22 [==============================] - 268s 12s/step - loss: 2.3068 - accuracy: 0.1000 - val_loss: 2.3053 - val_accuracy: 0.1000 - lr: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3b0bfa680>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "model1.fit([X_train_pad_seq,X_train_mask],y_train_int, batch_size=64, epochs=3, \n",
    "           validation_data=([X_test_pad_seq,X_test_mask], y_test_int), callbacks=[callbacks, metrics, tensorboard1],\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>At end of 3 epoch val_F1_score 0.10</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-19f9fc797342e40b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-19f9fc797342e40b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model1/model1_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd3a805d960>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation iou_score values\n",
    "import matplotlib.pyplot as plt\n",
    "his = pd.read_csv('model1/history.csv')\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['loss'])\n",
    "plt.plot(his['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b> From the above plot we can ensure that model is not overfitted</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
    "\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "B__rN4RjaNpc"
   },
   "outputs": [],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "\n",
    "\n",
    "X_train_spectrogram = np.array(convert_to_spectrogram(X_train_pad_seq))\n",
    "X_test_spectrogram = np.array(convert_to_spectrogram(X_test_pad_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 64, 35)\n",
      "(600, 64, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_spectrogram.shape)\n",
    "print(X_test_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1ynYZnaNpj"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "oniXBXcsaNpk",
    "outputId": "0f94ec35-98af-4b98-c501-35cbbfbd0a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_spectrogram():\n",
    "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
    "    return flag_shape\n",
    "grader_spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "(ex: Output from LSTM will be  (None, time_steps, features) average the output of every time step i.e, you should get (None,time_steps) \n",
    "and then pass to dense layer )\n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " X_train_pad_seq_input (Inpu  [(None, 64, 35)]         0         \n",
      " tLayer)                                                         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64, 120)           74880     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 120)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                7744      \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 64)                64        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,338\n",
      "Trainable params: 83,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# write the architecture of the model\n",
    "#print model.summary and make sure that it is following point 2 mentioned above\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_layer = Input(shape=(64, 35), name=\"X_train_pad_seq_input\", dtype='float32')\n",
    "\n",
    "lstm_output = LSTM(120, return_sequences=True, kernel_initializer=tf.keras.initializers.HeUniform())(input_layer)\n",
    "\n",
    "global_pooling = GlobalAveragePooling1D()(lstm_output)\n",
    "\n",
    "fc1 = Dense(64, kernel_initializer=tf.keras.initializers.HeUniform())(global_pooling)\n",
    "\n",
    "gelu_1 = tf.keras.layers.PReLU()(fc1)\n",
    "\n",
    "droup_1 = Dropout(0.2)(gelu_1)\n",
    "\n",
    "output = Dense(10,activation='softmax')(droup_1)\n",
    "\n",
    "model2 = Model(inputs = [input_layer], outputs = output) \n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model2, to_file='model2/model2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 64, 35)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.8\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.x_test = validation_data[0]\n",
    "        self.y_test = validation_data[1]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label = np.argmax(val_predict, axis = 1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label, average='micro')\n",
    "        print(\"val_F1_score: \", val_f1)\n",
    "        \n",
    "        \n",
    "        if(val_f1 > 0.80):\n",
    "            print(\"\\nReached %2.2f%% val_F1_score, so stopping training!!\" %(THRESHOLD))\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "        \n",
    "metrics = Metrics(validation_data=([X_test_spectrogram], y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 12:40:39.048308: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-03 12:40:39.048330: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-03 12:40:39.048437: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 12:40:39.048447: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-03 12:40:39.048452: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 12:40:39.048457: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-03 12:40:39.048600: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-03 12:40:39.048639: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-03 12:40:39.048644: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 12:40:39.048647: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    }
   ],
   "source": [
    "tensorboard2 = TensorBoard(log_dir='model2/model2_logs'.format(time()), histogram_freq=1, write_graph=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks2 = [\n",
    "    ModelCheckpoint(filepath='./model2/best_model_2.h5', save_weights_only = True, save_best_only = True, \\\n",
    "                                       mode = 'max', monitor = 'val_accuracy', verbose = 1),\n",
    "    #tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', patience = 1, mode = 'max', verbose = 1,factor=0.9),\n",
    "    tf.keras.callbacks.CSVLogger('./model2/history.csv'),\n",
    "]\n",
    "\n",
    "#compile model.\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0006),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      " 1/22 [>.............................] - ETA: 30s - loss: 2.4855 - accuracy: 0.1406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 12:41:07.930551: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-03 12:41:07.930584: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-03 12:41:07.930627: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 12:41:07.930634: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-03 12:41:07.930643: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 12:41:07.930647: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-03 12:41:08.060668: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-09-03 12:41:08.061841: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-03 12:41:08.061855: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 12:41:08.061860: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-09-03 12:41:08.081096: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 12:41:08.081116: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 12:41:08.081122: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-09-03 12:41:08.106824: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/22 [===>..........................] - ETA: 3s - loss: 2.5174 - accuracy: 0.1094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 12:41:08.143810: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08\n",
      "\n",
      "2022-09-03 12:41:08.173122: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.trace.json.gz\n",
      "2022-09-03 12:41:08.215991: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08\n",
      "\n",
      "2022-09-03 12:41:08.220813: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.memory_profile.json.gz\n",
      "2022-09-03 12:41:08.221435: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08\n",
      "Dumped tool data for xplane.pb to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model2/model2_logs/train/plugins/profile/2022_09_03_12_41_08/AI-iiitg.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/22 [===========================>..] - ETA: 0s - loss: 2.4031 - accuracy: 0.0990\n",
      "Epoch 1: val_accuracy improved from -inf to 0.11667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 1s 15ms/step\n",
      "val_F1_score:  0.11666666666666667\n",
      "22/22 [==============================] - 4s 131ms/step - loss: 2.3996 - accuracy: 0.1000 - val_loss: 2.3009 - val_accuracy: 0.1167\n",
      "Epoch 2/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.2978 - accuracy: 0.1164\n",
      "Epoch 2: val_accuracy improved from 0.11667 to 0.12500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.125\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 2.2978 - accuracy: 0.1164 - val_loss: 2.2635 - val_accuracy: 0.1250\n",
      "Epoch 3/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.2479 - accuracy: 0.1593\n",
      "Epoch 3: val_accuracy improved from 0.12500 to 0.15833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.15833333333333333\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 2.2479 - accuracy: 0.1593 - val_loss: 2.2371 - val_accuracy: 0.1583\n",
      "Epoch 4/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.2107 - accuracy: 0.1786\n",
      "Epoch 4: val_accuracy improved from 0.15833 to 0.20167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.20166666666666663\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 2.2107 - accuracy: 0.1786 - val_loss: 2.2071 - val_accuracy: 0.2017\n",
      "Epoch 5/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.1851 - accuracy: 0.1936\n",
      "Epoch 5: val_accuracy did not improve from 0.20167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.20000000000000004\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 2.1851 - accuracy: 0.1936 - val_loss: 2.1756 - val_accuracy: 0.2000\n",
      "Epoch 6/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.1352 - accuracy: 0.2250\n",
      "Epoch 6: val_accuracy did not improve from 0.20167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.20166666666666663\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 2.1352 - accuracy: 0.2250 - val_loss: 2.1487 - val_accuracy: 0.2017\n",
      "Epoch 7/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.1161 - accuracy: 0.2300\n",
      "Epoch 7: val_accuracy improved from 0.20167 to 0.21167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.21166666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 2.1161 - accuracy: 0.2300 - val_loss: 2.1258 - val_accuracy: 0.2117\n",
      "Epoch 8/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.0926 - accuracy: 0.2407\n",
      "Epoch 8: val_accuracy improved from 0.21167 to 0.24667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.2466666666666667\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 2.0926 - accuracy: 0.2407 - val_loss: 2.1005 - val_accuracy: 0.2467\n",
      "Epoch 9/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.0654 - accuracy: 0.2686\n",
      "Epoch 9: val_accuracy improved from 0.24667 to 0.25500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.255\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 2.0654 - accuracy: 0.2686 - val_loss: 2.0708 - val_accuracy: 0.2550\n",
      "Epoch 10/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.0290 - accuracy: 0.2764\n",
      "Epoch 10: val_accuracy improved from 0.25500 to 0.30167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.3016666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 2.0290 - accuracy: 0.2764 - val_loss: 2.0472 - val_accuracy: 0.3017\n",
      "Epoch 11/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.0166 - accuracy: 0.2779\n",
      "Epoch 11: val_accuracy did not improve from 0.30167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.2816666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 2.0166 - accuracy: 0.2779 - val_loss: 2.0412 - val_accuracy: 0.2817\n",
      "Epoch 12/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9868 - accuracy: 0.2957\n",
      "Epoch 12: val_accuracy did not improve from 0.30167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.3\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.9868 - accuracy: 0.2957 - val_loss: 2.0021 - val_accuracy: 0.3000\n",
      "Epoch 13/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9632 - accuracy: 0.3000\n",
      "Epoch 13: val_accuracy improved from 0.30167 to 0.33167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.33166666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.9632 - accuracy: 0.3000 - val_loss: 1.9687 - val_accuracy: 0.3317\n",
      "Epoch 14/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9164 - accuracy: 0.3250\n",
      "Epoch 14: val_accuracy did not improve from 0.33167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.3283333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.9164 - accuracy: 0.3250 - val_loss: 1.9482 - val_accuracy: 0.3283\n",
      "Epoch 15/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9024 - accuracy: 0.3286\n",
      "Epoch 15: val_accuracy improved from 0.33167 to 0.36000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.36\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.9024 - accuracy: 0.3286 - val_loss: 1.9207 - val_accuracy: 0.3600\n",
      "Epoch 16/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.8910 - accuracy: 0.3457\n",
      "Epoch 16: val_accuracy did not improve from 0.36000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.3516666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.8910 - accuracy: 0.3457 - val_loss: 1.8967 - val_accuracy: 0.3517\n",
      "Epoch 17/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.8493 - accuracy: 0.3400\n",
      "Epoch 17: val_accuracy did not improve from 0.36000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.35333333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.8493 - accuracy: 0.3400 - val_loss: 1.8845 - val_accuracy: 0.3533\n",
      "Epoch 18/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.8302 - accuracy: 0.3550\n",
      "Epoch 18: val_accuracy improved from 0.36000 to 0.36333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.3633333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.8302 - accuracy: 0.3550 - val_loss: 1.8780 - val_accuracy: 0.3633\n",
      "Epoch 19/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.8147 - accuracy: 0.3707\n",
      "Epoch 19: val_accuracy did not improve from 0.36333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.3616666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.8147 - accuracy: 0.3707 - val_loss: 1.8396 - val_accuracy: 0.3617\n",
      "Epoch 20/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.7844 - accuracy: 0.3586\n",
      "Epoch 20: val_accuracy did not improve from 0.36333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.36\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.7844 - accuracy: 0.3586 - val_loss: 1.8093 - val_accuracy: 0.3600\n",
      "Epoch 21/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.7470 - accuracy: 0.4000\n",
      "Epoch 21: val_accuracy did not improve from 0.36333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.35\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.7470 - accuracy: 0.4000 - val_loss: 1.8187 - val_accuracy: 0.3500\n",
      "Epoch 22/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.7280 - accuracy: 0.3936\n",
      "Epoch 22: val_accuracy improved from 0.36333 to 0.40000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.4000000000000001\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.7280 - accuracy: 0.3936 - val_loss: 1.7779 - val_accuracy: 0.4000\n",
      "Epoch 23/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.7143 - accuracy: 0.4029\n",
      "Epoch 23: val_accuracy improved from 0.40000 to 0.40667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.4066666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.7143 - accuracy: 0.4029 - val_loss: 1.7504 - val_accuracy: 0.4067\n",
      "Epoch 24/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.6765 - accuracy: 0.4243\n",
      "Epoch 24: val_accuracy improved from 0.40667 to 0.41000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.41\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.6765 - accuracy: 0.4243 - val_loss: 1.7567 - val_accuracy: 0.4100\n",
      "Epoch 25/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.6703 - accuracy: 0.4164\n",
      "Epoch 25: val_accuracy improved from 0.41000 to 0.42167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.42166666666666675\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.6703 - accuracy: 0.4164 - val_loss: 1.7170 - val_accuracy: 0.4217\n",
      "Epoch 26/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.6204 - accuracy: 0.4314\n",
      "Epoch 26: val_accuracy improved from 0.42167 to 0.46000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.46\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.6204 - accuracy: 0.4314 - val_loss: 1.6800 - val_accuracy: 0.4600\n",
      "Epoch 27/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.4507\n",
      "Epoch 27: val_accuracy improved from 0.46000 to 0.46667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.4666666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.6064 - accuracy: 0.4507 - val_loss: 1.6497 - val_accuracy: 0.4667\n",
      "Epoch 28/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5897 - accuracy: 0.4571\n",
      "Epoch 28: val_accuracy did not improve from 0.46667\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.4483333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.5897 - accuracy: 0.4571 - val_loss: 1.6441 - val_accuracy: 0.4483\n",
      "Epoch 29/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5836 - accuracy: 0.4486\n",
      "Epoch 29: val_accuracy improved from 0.46667 to 0.48167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.4816666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.5836 - accuracy: 0.4486 - val_loss: 1.6488 - val_accuracy: 0.4817\n",
      "Epoch 30/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5438 - accuracy: 0.4643\n",
      "Epoch 30: val_accuracy improved from 0.48167 to 0.49667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.49666666666666665\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.5438 - accuracy: 0.4643 - val_loss: 1.6010 - val_accuracy: 0.4967\n",
      "Epoch 31/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5211 - accuracy: 0.4836\n",
      "Epoch 31: val_accuracy did not improve from 0.49667\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.4866666666666667\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.5211 - accuracy: 0.4836 - val_loss: 1.5814 - val_accuracy: 0.4867\n",
      "Epoch 32/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5126 - accuracy: 0.4714\n",
      "Epoch 32: val_accuracy did not improve from 0.49667\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.48833333333333334\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 1.5126 - accuracy: 0.4714 - val_loss: 1.5863 - val_accuracy: 0.4883\n",
      "Epoch 33/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.5065 - accuracy: 0.4886\n",
      "Epoch 33: val_accuracy improved from 0.49667 to 0.50833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5083333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.5065 - accuracy: 0.4886 - val_loss: 1.5661 - val_accuracy: 0.5083\n",
      "Epoch 34/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4550 - accuracy: 0.5021\n",
      "Epoch 34: val_accuracy did not improve from 0.50833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.49833333333333335\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.4550 - accuracy: 0.5021 - val_loss: 1.5514 - val_accuracy: 0.4983\n",
      "Epoch 35/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4964\n",
      "Epoch 35: val_accuracy improved from 0.50833 to 0.52667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5266666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.4605 - accuracy: 0.4964 - val_loss: 1.5276 - val_accuracy: 0.5267\n",
      "Epoch 36/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4256 - accuracy: 0.5200\n",
      "Epoch 36: val_accuracy improved from 0.52667 to 0.53500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.535\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.4256 - accuracy: 0.5200 - val_loss: 1.5287 - val_accuracy: 0.5350\n",
      "Epoch 37/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.4071 - accuracy: 0.5186\n",
      "Epoch 37: val_accuracy improved from 0.53500 to 0.54833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.5483333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.4071 - accuracy: 0.5186 - val_loss: 1.4808 - val_accuracy: 0.5483\n",
      "Epoch 38/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.5250\n",
      "Epoch 38: val_accuracy did not improve from 0.54833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5366666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.3859 - accuracy: 0.5250 - val_loss: 1.5092 - val_accuracy: 0.5367\n",
      "Epoch 39/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3872 - accuracy: 0.5314\n",
      "Epoch 39: val_accuracy did not improve from 0.54833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.53\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.3872 - accuracy: 0.5314 - val_loss: 1.4748 - val_accuracy: 0.5300\n",
      "Epoch 40/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3603 - accuracy: 0.5457\n",
      "Epoch 40: val_accuracy did not improve from 0.54833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5216666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.3603 - accuracy: 0.5457 - val_loss: 1.4922 - val_accuracy: 0.5217\n",
      "Epoch 41/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3909 - accuracy: 0.5107\n",
      "Epoch 41: val_accuracy did not improve from 0.54833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5166666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.3909 - accuracy: 0.5107 - val_loss: 1.4916 - val_accuracy: 0.5167\n",
      "Epoch 42/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3437 - accuracy: 0.5429\n",
      "Epoch 42: val_accuracy did not improve from 0.54833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.545\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.3437 - accuracy: 0.5429 - val_loss: 1.4604 - val_accuracy: 0.5450\n",
      "Epoch 43/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3291 - accuracy: 0.5443\n",
      "Epoch 43: val_accuracy improved from 0.54833 to 0.57167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5716666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.3291 - accuracy: 0.5443 - val_loss: 1.4430 - val_accuracy: 0.5717\n",
      "Epoch 44/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3038 - accuracy: 0.5450\n",
      "Epoch 44: val_accuracy did not improve from 0.57167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.55\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.3038 - accuracy: 0.5450 - val_loss: 1.4408 - val_accuracy: 0.5500\n",
      "Epoch 45/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2852 - accuracy: 0.5793\n",
      "Epoch 45: val_accuracy did not improve from 0.57167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.5716666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2852 - accuracy: 0.5793 - val_loss: 1.4287 - val_accuracy: 0.5717\n",
      "Epoch 46/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2906 - accuracy: 0.5700\n",
      "Epoch 46: val_accuracy did not improve from 0.57167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.56\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 1.2906 - accuracy: 0.5700 - val_loss: 1.4211 - val_accuracy: 0.5600\n",
      "Epoch 47/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2538 - accuracy: 0.5700\n",
      "Epoch 47: val_accuracy did not improve from 0.57167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.545\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2538 - accuracy: 0.5700 - val_loss: 1.4208 - val_accuracy: 0.5450\n",
      "Epoch 48/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2427 - accuracy: 0.5850\n",
      "Epoch 48: val_accuracy did not improve from 0.57167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5683333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.2427 - accuracy: 0.5850 - val_loss: 1.4128 - val_accuracy: 0.5683\n",
      "Epoch 49/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 1.2503 - accuracy: 0.5647\n",
      "Epoch 49: val_accuracy improved from 0.57167 to 0.58500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.585\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2531 - accuracy: 0.5621 - val_loss: 1.3495 - val_accuracy: 0.5850\n",
      "Epoch 50/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2391 - accuracy: 0.5700\n",
      "Epoch 50: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.5666666666666667\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.2391 - accuracy: 0.5700 - val_loss: 1.3887 - val_accuracy: 0.5667\n",
      "Epoch 51/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2432 - accuracy: 0.5650\n",
      "Epoch 51: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5583333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.2432 - accuracy: 0.5650 - val_loss: 1.3772 - val_accuracy: 0.5583\n",
      "Epoch 52/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2337 - accuracy: 0.5729\n",
      "Epoch 52: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.57\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2337 - accuracy: 0.5729 - val_loss: 1.3489 - val_accuracy: 0.5700\n",
      "Epoch 53/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.2067 - accuracy: 0.5886\n",
      "Epoch 53: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.58\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2067 - accuracy: 0.5886 - val_loss: 1.3291 - val_accuracy: 0.5800\n",
      "Epoch 54/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1911 - accuracy: 0.5971\n",
      "Epoch 54: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5466666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.1911 - accuracy: 0.5971 - val_loss: 1.3588 - val_accuracy: 0.5467\n",
      "Epoch 55/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1895 - accuracy: 0.6043\n",
      "Epoch 55: val_accuracy did not improve from 0.58500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5833333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.1895 - accuracy: 0.6043 - val_loss: 1.3204 - val_accuracy: 0.5833\n",
      "Epoch 56/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.6043\n",
      "Epoch 56: val_accuracy improved from 0.58500 to 0.59333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5933333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.1676 - accuracy: 0.6043 - val_loss: 1.3102 - val_accuracy: 0.5933\n",
      "Epoch 57/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1544 - accuracy: 0.5871\n",
      "Epoch 57: val_accuracy improved from 0.59333 to 0.60833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6083333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.1544 - accuracy: 0.5871 - val_loss: 1.2844 - val_accuracy: 0.6083\n",
      "Epoch 58/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1344 - accuracy: 0.6129\n",
      "Epoch 58: val_accuracy improved from 0.60833 to 0.62500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.625\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.1344 - accuracy: 0.6129 - val_loss: 1.2811 - val_accuracy: 0.6250\n",
      "Epoch 59/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1291 - accuracy: 0.6286\n",
      "Epoch 59: val_accuracy did not improve from 0.62500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6033333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.1291 - accuracy: 0.6286 - val_loss: 1.2706 - val_accuracy: 0.6033\n",
      "Epoch 60/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.1154 - accuracy: 0.6121\n",
      "Epoch 60: val_accuracy did not improve from 0.62500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.61\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.1154 - accuracy: 0.6121 - val_loss: 1.2876 - val_accuracy: 0.6100\n",
      "Epoch 61/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0916 - accuracy: 0.6336\n",
      "Epoch 61: val_accuracy did not improve from 0.62500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6016666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.0916 - accuracy: 0.6336 - val_loss: 1.2539 - val_accuracy: 0.6017\n",
      "Epoch 62/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.6300\n",
      "Epoch 62: val_accuracy did not improve from 0.62500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5966666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.0921 - accuracy: 0.6300 - val_loss: 1.2577 - val_accuracy: 0.5967\n",
      "Epoch 63/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0717 - accuracy: 0.6421\n",
      "Epoch 63: val_accuracy did not improve from 0.62500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.62\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.0717 - accuracy: 0.6421 - val_loss: 1.2592 - val_accuracy: 0.6200\n",
      "Epoch 64/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0869 - accuracy: 0.6286\n",
      "Epoch 64: val_accuracy improved from 0.62500 to 0.62667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6266666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.0869 - accuracy: 0.6286 - val_loss: 1.2185 - val_accuracy: 0.6267\n",
      "Epoch 65/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0659 - accuracy: 0.6329\n",
      "Epoch 65: val_accuracy improved from 0.62667 to 0.63333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6333333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.0659 - accuracy: 0.6329 - val_loss: 1.1968 - val_accuracy: 0.6333\n",
      "Epoch 66/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.6386\n",
      "Epoch 66: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6083333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0600 - accuracy: 0.6386 - val_loss: 1.2545 - val_accuracy: 0.6083\n",
      "Epoch 67/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0541 - accuracy: 0.6364\n",
      "Epoch 67: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.6033333333333334\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.0541 - accuracy: 0.6364 - val_loss: 1.2413 - val_accuracy: 0.6033\n",
      "Epoch 68/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0465 - accuracy: 0.6386\n",
      "Epoch 68: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6116666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0465 - accuracy: 0.6386 - val_loss: 1.2559 - val_accuracy: 0.6117\n",
      "Epoch 69/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.6550\n",
      "Epoch 69: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6116666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0440 - accuracy: 0.6550 - val_loss: 1.2222 - val_accuracy: 0.6117\n",
      "Epoch 70/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0224 - accuracy: 0.6564\n",
      "Epoch 70: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6016666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0224 - accuracy: 0.6564 - val_loss: 1.2420 - val_accuracy: 0.6017\n",
      "Epoch 71/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.6621\n",
      "Epoch 71: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6283333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.0217 - accuracy: 0.6621 - val_loss: 1.2015 - val_accuracy: 0.6283\n",
      "Epoch 72/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.6557\n",
      "Epoch 72: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6316666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9950 - accuracy: 0.6557 - val_loss: 1.1793 - val_accuracy: 0.6317\n",
      "Epoch 73/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.6586\n",
      "Epoch 73: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6233333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 1.0087 - accuracy: 0.6586 - val_loss: 1.2058 - val_accuracy: 0.6233\n",
      "Epoch 74/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.6693\n",
      "Epoch 74: val_accuracy did not improve from 0.63333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6233333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9852 - accuracy: 0.6693 - val_loss: 1.1774 - val_accuracy: 0.6233\n",
      "Epoch 75/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6714\n",
      "Epoch 75: val_accuracy improved from 0.63333 to 0.65333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6533333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0006 - accuracy: 0.6714 - val_loss: 1.1670 - val_accuracy: 0.6533\n",
      "Epoch 76/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.6793\n",
      "Epoch 76: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.62\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.9758 - accuracy: 0.6793 - val_loss: 1.1938 - val_accuracy: 0.6200\n",
      "Epoch 77/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9782 - accuracy: 0.6636\n",
      "Epoch 77: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6166666666666667\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.9782 - accuracy: 0.6636 - val_loss: 1.2292 - val_accuracy: 0.6167\n",
      "Epoch 78/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9916 - accuracy: 0.6707\n",
      "Epoch 78: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6283333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9916 - accuracy: 0.6707 - val_loss: 1.1703 - val_accuracy: 0.6283\n",
      "Epoch 79/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9435 - accuracy: 0.6929\n",
      "Epoch 79: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6266666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9435 - accuracy: 0.6929 - val_loss: 1.1782 - val_accuracy: 0.6267\n",
      "Epoch 80/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9424 - accuracy: 0.6821\n",
      "Epoch 80: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.64\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.9424 - accuracy: 0.6821 - val_loss: 1.1348 - val_accuracy: 0.6400\n",
      "Epoch 81/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9243 - accuracy: 0.6836\n",
      "Epoch 81: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6433333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.9243 - accuracy: 0.6836 - val_loss: 1.1544 - val_accuracy: 0.6433\n",
      "Epoch 82/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9221 - accuracy: 0.6857\n",
      "Epoch 82: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6116666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.9221 - accuracy: 0.6857 - val_loss: 1.1832 - val_accuracy: 0.6117\n",
      "Epoch 83/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9127 - accuracy: 0.6957\n",
      "Epoch 83: val_accuracy did not improve from 0.65333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.64\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9127 - accuracy: 0.6957 - val_loss: 1.1714 - val_accuracy: 0.6400\n",
      "Epoch 84/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.6886\n",
      "Epoch 84: val_accuracy improved from 0.65333 to 0.65667, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6566666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9307 - accuracy: 0.6886 - val_loss: 1.1209 - val_accuracy: 0.6567\n",
      "Epoch 85/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9105 - accuracy: 0.6900\n",
      "Epoch 85: val_accuracy did not improve from 0.65667\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.65\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.9105 - accuracy: 0.6900 - val_loss: 1.1517 - val_accuracy: 0.6500\n",
      "Epoch 86/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9062 - accuracy: 0.6971\n",
      "Epoch 86: val_accuracy did not improve from 0.65667\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.65\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.9062 - accuracy: 0.6971 - val_loss: 1.1046 - val_accuracy: 0.6500\n",
      "Epoch 87/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.6800\n",
      "Epoch 87: val_accuracy did not improve from 0.65667\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.645\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.9094 - accuracy: 0.6800 - val_loss: 1.1236 - val_accuracy: 0.6450\n",
      "Epoch 88/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8960 - accuracy: 0.6929\n",
      "Epoch 88: val_accuracy did not improve from 0.65667\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6333333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.8960 - accuracy: 0.6929 - val_loss: 1.1332 - val_accuracy: 0.6333\n",
      "Epoch 89/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8805 - accuracy: 0.7007\n",
      "Epoch 89: val_accuracy improved from 0.65667 to 0.66333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 12ms/step\n",
      "val_F1_score:  0.6633333333333333\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.8805 - accuracy: 0.7007 - val_loss: 1.1145 - val_accuracy: 0.6633\n",
      "Epoch 90/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.8924 - accuracy: 0.6882\n",
      "Epoch 90: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.645\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.8953 - accuracy: 0.6871 - val_loss: 1.0948 - val_accuracy: 0.6450\n",
      "Epoch 91/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8679 - accuracy: 0.7150\n",
      "Epoch 91: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.635\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.8679 - accuracy: 0.7150 - val_loss: 1.1142 - val_accuracy: 0.6350\n",
      "Epoch 92/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.7057\n",
      "Epoch 92: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6566666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.8564 - accuracy: 0.7057 - val_loss: 1.0595 - val_accuracy: 0.6567\n",
      "Epoch 93/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.7164\n",
      "Epoch 93: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.65\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.8548 - accuracy: 0.7164 - val_loss: 1.1506 - val_accuracy: 0.6500\n",
      "Epoch 94/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.7029\n",
      "Epoch 94: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6566666666666666\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.8410 - accuracy: 0.7029 - val_loss: 1.0740 - val_accuracy: 0.6567\n",
      "Epoch 95/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.7100\n",
      "Epoch 95: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6416666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.8471 - accuracy: 0.7100 - val_loss: 1.1273 - val_accuracy: 0.6417\n",
      "Epoch 96/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.7093\n",
      "Epoch 96: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.65\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.8453 - accuracy: 0.7093 - val_loss: 1.1359 - val_accuracy: 0.6500\n",
      "Epoch 97/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8202 - accuracy: 0.7243\n",
      "Epoch 97: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.64\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.8202 - accuracy: 0.7243 - val_loss: 1.1484 - val_accuracy: 0.6400\n",
      "Epoch 98/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8311 - accuracy: 0.7321\n",
      "Epoch 98: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.66\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8311 - accuracy: 0.7321 - val_loss: 1.1054 - val_accuracy: 0.6600\n",
      "Epoch 99/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.7321\n",
      "Epoch 99: val_accuracy did not improve from 0.66333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6466666666666666\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.8194 - accuracy: 0.7321 - val_loss: 1.1231 - val_accuracy: 0.6467\n",
      "Epoch 100/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.7364\n",
      "Epoch 100: val_accuracy improved from 0.66333 to 0.67833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6783333333333333\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.8011 - accuracy: 0.7364 - val_loss: 1.0840 - val_accuracy: 0.6783\n",
      "Epoch 101/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.8010 - accuracy: 0.7210\n",
      "Epoch 101: val_accuracy did not improve from 0.67833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.675\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8107 - accuracy: 0.7214 - val_loss: 1.0791 - val_accuracy: 0.6750\n",
      "Epoch 102/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8444 - accuracy: 0.7079\n",
      "Epoch 102: val_accuracy did not improve from 0.67833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6616666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.8444 - accuracy: 0.7079 - val_loss: 1.0492 - val_accuracy: 0.6617\n",
      "Epoch 103/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.7300\n",
      "Epoch 103: val_accuracy improved from 0.67833 to 0.68000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.68\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.8089 - accuracy: 0.7300 - val_loss: 1.0716 - val_accuracy: 0.6800\n",
      "Epoch 104/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7828 - accuracy: 0.7400\n",
      "Epoch 104: val_accuracy improved from 0.68000 to 0.68333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6833333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7828 - accuracy: 0.7400 - val_loss: 1.0410 - val_accuracy: 0.6833\n",
      "Epoch 105/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.7357\n",
      "Epoch 105: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.655\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7980 - accuracy: 0.7357 - val_loss: 1.1173 - val_accuracy: 0.6550\n",
      "Epoch 106/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7987 - accuracy: 0.7364\n",
      "Epoch 106: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6666666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7987 - accuracy: 0.7364 - val_loss: 1.0859 - val_accuracy: 0.6667\n",
      "Epoch 107/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.7429\n",
      "Epoch 107: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.6733333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7701 - accuracy: 0.7429 - val_loss: 1.0693 - val_accuracy: 0.6733\n",
      "Epoch 108/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7776 - accuracy: 0.7329\n",
      "Epoch 108: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6766666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7776 - accuracy: 0.7329 - val_loss: 1.0331 - val_accuracy: 0.6767\n",
      "Epoch 109/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7755 - accuracy: 0.7407\n",
      "Epoch 109: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6816666666666666\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7755 - accuracy: 0.7407 - val_loss: 1.0235 - val_accuracy: 0.6817\n",
      "Epoch 110/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.7271\n",
      "Epoch 110: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.675\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7923 - accuracy: 0.7271 - val_loss: 1.0363 - val_accuracy: 0.6750\n",
      "Epoch 111/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.7329\n",
      "Epoch 111: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.68\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.7849 - accuracy: 0.7329 - val_loss: 1.0127 - val_accuracy: 0.6800\n",
      "Epoch 112/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.7364\n",
      "Epoch 112: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6816666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7777 - accuracy: 0.7364 - val_loss: 1.0193 - val_accuracy: 0.6817\n",
      "Epoch 113/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.7464\n",
      "Epoch 113: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.665\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7542 - accuracy: 0.7464 - val_loss: 1.0483 - val_accuracy: 0.6650\n",
      "Epoch 114/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7519 - accuracy: 0.7479\n",
      "Epoch 114: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6833333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.7519 - accuracy: 0.7479 - val_loss: 1.0238 - val_accuracy: 0.6833\n",
      "Epoch 115/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.7543\n",
      "Epoch 115: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6833333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7472 - accuracy: 0.7543 - val_loss: 1.0475 - val_accuracy: 0.6833\n",
      "Epoch 116/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.7429\n",
      "Epoch 116: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6833333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7531 - accuracy: 0.7429 - val_loss: 1.0203 - val_accuracy: 0.6833\n",
      "Epoch 117/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7534 - accuracy: 0.7471\n",
      "Epoch 117: val_accuracy did not improve from 0.68333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6766666666666666\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.7534 - accuracy: 0.7471 - val_loss: 1.0377 - val_accuracy: 0.6767\n",
      "Epoch 118/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7277 - accuracy: 0.7586\n",
      "Epoch 118: val_accuracy improved from 0.68333 to 0.69833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6983333333333334\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7277 - accuracy: 0.7586 - val_loss: 1.0364 - val_accuracy: 0.6983\n",
      "Epoch 119/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.7629\n",
      "Epoch 119: val_accuracy improved from 0.69833 to 0.70000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7013 - accuracy: 0.7629 - val_loss: 1.0344 - val_accuracy: 0.7000\n",
      "Epoch 120/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7265 - accuracy: 0.7586\n",
      "Epoch 120: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6616666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7265 - accuracy: 0.7586 - val_loss: 1.0546 - val_accuracy: 0.6617\n",
      "Epoch 121/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.7479\n",
      "Epoch 121: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.68\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7485 - accuracy: 0.7479 - val_loss: 1.0275 - val_accuracy: 0.6800\n",
      "Epoch 122/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7779\n",
      "Epoch 122: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.66\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7052 - accuracy: 0.7779 - val_loss: 1.0438 - val_accuracy: 0.6600\n",
      "Epoch 123/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.7571\n",
      "Epoch 123: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6933333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7276 - accuracy: 0.7571 - val_loss: 0.9704 - val_accuracy: 0.6933\n",
      "Epoch 124/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.7024 - accuracy: 0.7753\n",
      "Epoch 124: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.685\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7039 - accuracy: 0.7729 - val_loss: 1.0284 - val_accuracy: 0.6850\n",
      "Epoch 125/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6984 - accuracy: 0.7664\n",
      "Epoch 125: val_accuracy did not improve from 0.70000\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.6966666666666667\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6984 - accuracy: 0.7664 - val_loss: 0.9909 - val_accuracy: 0.6967\n",
      "Epoch 126/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.7457\n",
      "Epoch 126: val_accuracy improved from 0.70000 to 0.71833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7183333333333334\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.7009 - accuracy: 0.7457 - val_loss: 0.9862 - val_accuracy: 0.7183\n",
      "Epoch 127/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.7821\n",
      "Epoch 127: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.695\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6810 - accuracy: 0.7821 - val_loss: 0.9741 - val_accuracy: 0.6950\n",
      "Epoch 128/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6733 - accuracy: 0.7800\n",
      "Epoch 128: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6933333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6733 - accuracy: 0.7800 - val_loss: 1.0092 - val_accuracy: 0.6933\n",
      "Epoch 129/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.7729\n",
      "Epoch 129: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6866666666666666\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6922 - accuracy: 0.7729 - val_loss: 0.9961 - val_accuracy: 0.6867\n",
      "Epoch 130/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6677 - accuracy: 0.7821\n",
      "Epoch 130: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7033333333333334\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.6677 - accuracy: 0.7821 - val_loss: 0.9783 - val_accuracy: 0.7033\n",
      "Epoch 131/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.7650\n",
      "Epoch 131: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6783333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6870 - accuracy: 0.7650 - val_loss: 1.0335 - val_accuracy: 0.6783\n",
      "Epoch 132/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.7736\n",
      "Epoch 132: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6983333333333334\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6735 - accuracy: 0.7736 - val_loss: 1.0009 - val_accuracy: 0.6983\n",
      "Epoch 133/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7821\n",
      "Epoch 133: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7033333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6588 - accuracy: 0.7821 - val_loss: 0.9688 - val_accuracy: 0.7033\n",
      "Epoch 134/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7700\n",
      "Epoch 134: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6583333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6667 - accuracy: 0.7700 - val_loss: 1.0749 - val_accuracy: 0.6583\n",
      "Epoch 135/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7063 - accuracy: 0.7593\n",
      "Epoch 135: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6833333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7063 - accuracy: 0.7593 - val_loss: 1.0279 - val_accuracy: 0.6833\n",
      "Epoch 136/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.7721\n",
      "Epoch 136: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7016666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6654 - accuracy: 0.7721 - val_loss: 1.0212 - val_accuracy: 0.7017\n",
      "Epoch 137/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7836\n",
      "Epoch 137: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6933333333333334\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6540 - accuracy: 0.7836 - val_loss: 1.0192 - val_accuracy: 0.6933\n",
      "Epoch 138/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.7664\n",
      "Epoch 138: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7083333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6629 - accuracy: 0.7664 - val_loss: 0.9988 - val_accuracy: 0.7083\n",
      "Epoch 139/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.7871\n",
      "Epoch 139: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6916666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6491 - accuracy: 0.7871 - val_loss: 0.9884 - val_accuracy: 0.6917\n",
      "Epoch 140/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.7750\n",
      "Epoch 140: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7116666666666667\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6554 - accuracy: 0.7750 - val_loss: 0.9786 - val_accuracy: 0.7117\n",
      "Epoch 141/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.7821\n",
      "Epoch 141: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6469 - accuracy: 0.7821 - val_loss: 0.9858 - val_accuracy: 0.7100\n",
      "Epoch 142/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.7879\n",
      "Epoch 142: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6933333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6213 - accuracy: 0.7879 - val_loss: 0.9962 - val_accuracy: 0.6933\n",
      "Epoch 143/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6478 - accuracy: 0.7879\n",
      "Epoch 143: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6983333333333334\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6478 - accuracy: 0.7879 - val_loss: 0.9817 - val_accuracy: 0.6983\n",
      "Epoch 144/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.8050\n",
      "Epoch 144: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6137 - accuracy: 0.8050 - val_loss: 0.9653 - val_accuracy: 0.7100\n",
      "Epoch 145/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6332 - accuracy: 0.7893\n",
      "Epoch 145: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7033333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6332 - accuracy: 0.7893 - val_loss: 0.9820 - val_accuracy: 0.7033\n",
      "Epoch 146/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.8036\n",
      "Epoch 146: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7066666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6069 - accuracy: 0.8036 - val_loss: 0.9759 - val_accuracy: 0.7067\n",
      "Epoch 147/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.7929\n",
      "Epoch 147: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6933333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6264 - accuracy: 0.7929 - val_loss: 1.0397 - val_accuracy: 0.6933\n",
      "Epoch 148/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.7907\n",
      "Epoch 148: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6916666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6244 - accuracy: 0.7907 - val_loss: 0.9994 - val_accuracy: 0.6917\n",
      "Epoch 149/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7671\n",
      "Epoch 149: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6916666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6595 - accuracy: 0.7671 - val_loss: 1.0230 - val_accuracy: 0.6917\n",
      "Epoch 150/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7871\n",
      "Epoch 150: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.6983333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6290 - accuracy: 0.7871 - val_loss: 0.9748 - val_accuracy: 0.6983\n",
      "Epoch 151/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.7979\n",
      "Epoch 151: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.705\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6141 - accuracy: 0.7979 - val_loss: 0.9777 - val_accuracy: 0.7050\n",
      "Epoch 152/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7779\n",
      "Epoch 152: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7016666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6375 - accuracy: 0.7779 - val_loss: 0.9492 - val_accuracy: 0.7017\n",
      "Epoch 153/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.7929\n",
      "Epoch 153: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7183333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6086 - accuracy: 0.7929 - val_loss: 0.9254 - val_accuracy: 0.7183\n",
      "Epoch 154/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.8071\n",
      "Epoch 154: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7183333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5973 - accuracy: 0.8071 - val_loss: 0.9481 - val_accuracy: 0.7183\n",
      "Epoch 155/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.8014\n",
      "Epoch 155: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7083333333333334\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5978 - accuracy: 0.8014 - val_loss: 0.9759 - val_accuracy: 0.7083\n",
      "Epoch 156/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.7964\n",
      "Epoch 156: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.68\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6104 - accuracy: 0.7964 - val_loss: 0.9935 - val_accuracy: 0.6800\n",
      "Epoch 157/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.7843\n",
      "Epoch 157: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.685\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6313 - accuracy: 0.7843 - val_loss: 1.0283 - val_accuracy: 0.6850\n",
      "Epoch 158/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7936\n",
      "Epoch 158: val_accuracy did not improve from 0.71833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7083333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6107 - accuracy: 0.7936 - val_loss: 0.9795 - val_accuracy: 0.7083\n",
      "Epoch 159/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.8221\n",
      "Epoch 159: val_accuracy improved from 0.71833 to 0.72167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7216666666666668\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5771 - accuracy: 0.8221 - val_loss: 0.9526 - val_accuracy: 0.7217\n",
      "Epoch 160/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.8136\n",
      "Epoch 160: val_accuracy did not improve from 0.72167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7183333333333334\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5679 - accuracy: 0.8136 - val_loss: 0.9509 - val_accuracy: 0.7183\n",
      "Epoch 161/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.7993\n",
      "Epoch 161: val_accuracy did not improve from 0.72167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.705\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5924 - accuracy: 0.7993 - val_loss: 0.9473 - val_accuracy: 0.7050\n",
      "Epoch 162/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.8021\n",
      "Epoch 162: val_accuracy improved from 0.72167 to 0.73500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.735\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5868 - accuracy: 0.8021 - val_loss: 0.9345 - val_accuracy: 0.7350\n",
      "Epoch 163/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.8071\n",
      "Epoch 163: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.715\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5785 - accuracy: 0.8071 - val_loss: 0.9514 - val_accuracy: 0.7150\n",
      "Epoch 164/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.8079\n",
      "Epoch 164: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7066666666666667\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5844 - accuracy: 0.8079 - val_loss: 1.0110 - val_accuracy: 0.7067\n",
      "Epoch 165/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.8136\n",
      "Epoch 165: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7033333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5749 - accuracy: 0.8136 - val_loss: 0.9982 - val_accuracy: 0.7033\n",
      "Epoch 166/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.8050\n",
      "Epoch 166: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5710 - accuracy: 0.8050 - val_loss: 0.9811 - val_accuracy: 0.7100\n",
      "Epoch 167/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.8043\n",
      "Epoch 167: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7083333333333334\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5820 - accuracy: 0.8043 - val_loss: 0.9585 - val_accuracy: 0.7083\n",
      "Epoch 168/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.8164\n",
      "Epoch 168: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7250000000000001\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5494 - accuracy: 0.8164 - val_loss: 0.9433 - val_accuracy: 0.7250\n",
      "Epoch 169/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.8121\n",
      "Epoch 169: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7116666666666667\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5723 - accuracy: 0.8121 - val_loss: 0.9259 - val_accuracy: 0.7117\n",
      "Epoch 170/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.5726 - accuracy: 0.8125\n",
      "Epoch 170: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.72\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5755 - accuracy: 0.8129 - val_loss: 0.9650 - val_accuracy: 0.7200\n",
      "Epoch 171/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.7986\n",
      "Epoch 171: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6966666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5757 - accuracy: 0.7986 - val_loss: 1.0103 - val_accuracy: 0.6967\n",
      "Epoch 172/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.7964\n",
      "Epoch 172: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5877 - accuracy: 0.7964 - val_loss: 0.9147 - val_accuracy: 0.7300\n",
      "Epoch 173/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8207\n",
      "Epoch 173: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7316666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5384 - accuracy: 0.8207 - val_loss: 0.9573 - val_accuracy: 0.7317\n",
      "Epoch 174/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8150\n",
      "Epoch 174: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5331 - accuracy: 0.8150 - val_loss: 0.8942 - val_accuracy: 0.7267\n",
      "Epoch 175/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.8221\n",
      "Epoch 175: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5395 - accuracy: 0.8221 - val_loss: 0.9466 - val_accuracy: 0.7233\n",
      "Epoch 176/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.8250\n",
      "Epoch 176: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7133333333333335\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5408 - accuracy: 0.8250 - val_loss: 0.9453 - val_accuracy: 0.7133\n",
      "Epoch 177/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8143\n",
      "Epoch 177: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7250000000000001\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5417 - accuracy: 0.8143 - val_loss: 0.9346 - val_accuracy: 0.7250\n",
      "Epoch 178/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.8200\n",
      "Epoch 178: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5211 - accuracy: 0.8200 - val_loss: 0.9665 - val_accuracy: 0.7100\n",
      "Epoch 179/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8200\n",
      "Epoch 179: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5359 - accuracy: 0.8200 - val_loss: 0.9640 - val_accuracy: 0.7267\n",
      "Epoch 180/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8286\n",
      "Epoch 180: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7216666666666668\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5280 - accuracy: 0.8286 - val_loss: 0.9507 - val_accuracy: 0.7217\n",
      "Epoch 181/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.8307\n",
      "Epoch 181: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7116666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4987 - accuracy: 0.8307 - val_loss: 0.9433 - val_accuracy: 0.7117\n",
      "Epoch 182/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8114\n",
      "Epoch 182: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.705\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5550 - accuracy: 0.8114 - val_loss: 0.9740 - val_accuracy: 0.7050\n",
      "Epoch 183/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.8186\n",
      "Epoch 183: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7216666666666668\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5354 - accuracy: 0.8186 - val_loss: 0.9503 - val_accuracy: 0.7217\n",
      "Epoch 184/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.8164\n",
      "Epoch 184: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5370 - accuracy: 0.8164 - val_loss: 0.9353 - val_accuracy: 0.7233\n",
      "Epoch 185/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8071\n",
      "Epoch 185: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5304 - accuracy: 0.8071 - val_loss: 0.9466 - val_accuracy: 0.7333\n",
      "Epoch 186/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.8286\n",
      "Epoch 186: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.72\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5110 - accuracy: 0.8286 - val_loss: 0.9706 - val_accuracy: 0.7200\n",
      "Epoch 187/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.8179\n",
      "Epoch 187: val_accuracy did not improve from 0.73500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7250000000000001\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5116 - accuracy: 0.8179 - val_loss: 0.9284 - val_accuracy: 0.7250\n",
      "Epoch 188/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8257\n",
      "Epoch 188: val_accuracy improved from 0.73500 to 0.74167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5242 - accuracy: 0.8257 - val_loss: 0.9152 - val_accuracy: 0.7417\n",
      "Epoch 189/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.5012 - accuracy: 0.8378\n",
      "Epoch 189: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.74\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.5026 - accuracy: 0.8357 - val_loss: 0.9161 - val_accuracy: 0.7400\n",
      "Epoch 190/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.8257\n",
      "Epoch 190: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5111 - accuracy: 0.8257 - val_loss: 0.9228 - val_accuracy: 0.7267\n",
      "Epoch 191/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.8321\n",
      "Epoch 191: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7383333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5115 - accuracy: 0.8321 - val_loss: 0.9462 - val_accuracy: 0.7383\n",
      "Epoch 192/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.8321\n",
      "Epoch 192: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7183333333333334\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5072 - accuracy: 0.8321 - val_loss: 0.9647 - val_accuracy: 0.7183\n",
      "Epoch 193/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.8221\n",
      "Epoch 193: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5119 - accuracy: 0.8221 - val_loss: 0.9528 - val_accuracy: 0.7233\n",
      "Epoch 194/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8214\n",
      "Epoch 194: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5493 - accuracy: 0.8214 - val_loss: 0.9261 - val_accuracy: 0.7233\n",
      "Epoch 195/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.5199 - accuracy: 0.8229\n",
      "Epoch 195: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7283333333333334\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 0.5134 - accuracy: 0.8257 - val_loss: 0.8994 - val_accuracy: 0.7283\n",
      "Epoch 196/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.4967 - accuracy: 0.8341\n",
      "Epoch 196: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.4971 - accuracy: 0.8321 - val_loss: 0.9244 - val_accuracy: 0.7267\n",
      "Epoch 197/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.8357\n",
      "Epoch 197: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4878 - accuracy: 0.8357 - val_loss: 0.9529 - val_accuracy: 0.7233\n",
      "Epoch 198/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.8357\n",
      "Epoch 198: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7283333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4822 - accuracy: 0.8357 - val_loss: 0.9149 - val_accuracy: 0.7283\n",
      "Epoch 199/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8550\n",
      "Epoch 199: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.735\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4520 - accuracy: 0.8550 - val_loss: 0.9035 - val_accuracy: 0.7350\n",
      "Epoch 200/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.8414\n",
      "Epoch 200: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7383333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4810 - accuracy: 0.8414 - val_loss: 0.9168 - val_accuracy: 0.7383\n",
      "Epoch 201/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8314\n",
      "Epoch 201: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5078 - accuracy: 0.8314 - val_loss: 0.9161 - val_accuracy: 0.7333\n",
      "Epoch 202/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.8493\n",
      "Epoch 202: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4695 - accuracy: 0.8493 - val_loss: 0.8760 - val_accuracy: 0.7333\n",
      "Epoch 203/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8486\n",
      "Epoch 203: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4688 - accuracy: 0.8486 - val_loss: 0.9961 - val_accuracy: 0.7100\n",
      "Epoch 204/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8514\n",
      "Epoch 204: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7383333333333333\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4535 - accuracy: 0.8514 - val_loss: 0.9131 - val_accuracy: 0.7383\n",
      "Epoch 205/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8493\n",
      "Epoch 205: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4575 - accuracy: 0.8493 - val_loss: 0.9466 - val_accuracy: 0.7267\n",
      "Epoch 206/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.8507\n",
      "Epoch 206: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4666 - accuracy: 0.8507 - val_loss: 0.9067 - val_accuracy: 0.7333\n",
      "Epoch 207/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8464\n",
      "Epoch 207: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.74\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4508 - accuracy: 0.8464 - val_loss: 0.8787 - val_accuracy: 0.7400\n",
      "Epoch 208/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.8514\n",
      "Epoch 208: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7233333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4441 - accuracy: 0.8514 - val_loss: 0.9101 - val_accuracy: 0.7233\n",
      "Epoch 209/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8493\n",
      "Epoch 209: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7283333333333334\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4582 - accuracy: 0.8493 - val_loss: 0.9417 - val_accuracy: 0.7283\n",
      "Epoch 210/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.8493\n",
      "Epoch 210: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4630 - accuracy: 0.8493 - val_loss: 0.8942 - val_accuracy: 0.7367\n",
      "Epoch 211/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.8593\n",
      "Epoch 211: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4295 - accuracy: 0.8593 - val_loss: 0.9022 - val_accuracy: 0.7367\n",
      "Epoch 212/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.8407\n",
      "Epoch 212: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4678 - accuracy: 0.8407 - val_loss: 0.9366 - val_accuracy: 0.7367\n",
      "Epoch 213/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.8421\n",
      "Epoch 213: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7266666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4735 - accuracy: 0.8421 - val_loss: 0.9186 - val_accuracy: 0.7267\n",
      "Epoch 214/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.8500\n",
      "Epoch 214: val_accuracy did not improve from 0.74167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7216666666666668\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4596 - accuracy: 0.8500 - val_loss: 0.9725 - val_accuracy: 0.7217\n",
      "Epoch 215/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8521\n",
      "Epoch 215: val_accuracy improved from 0.74167 to 0.75333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4628 - accuracy: 0.8521 - val_loss: 0.8904 - val_accuracy: 0.7533\n",
      "Epoch 216/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.8364\n",
      "Epoch 216: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7216666666666668\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4703 - accuracy: 0.8364 - val_loss: 0.9756 - val_accuracy: 0.7217\n",
      "Epoch 217/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8350\n",
      "Epoch 217: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7383333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4990 - accuracy: 0.8350 - val_loss: 0.9394 - val_accuracy: 0.7383\n",
      "Epoch 218/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8321\n",
      "Epoch 218: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7483333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4746 - accuracy: 0.8321 - val_loss: 0.9114 - val_accuracy: 0.7483\n",
      "Epoch 219/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8450\n",
      "Epoch 219: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4539 - accuracy: 0.8450 - val_loss: 0.9079 - val_accuracy: 0.7450\n",
      "Epoch 220/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8600\n",
      "Epoch 220: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4306 - accuracy: 0.8600 - val_loss: 0.9381 - val_accuracy: 0.7300\n",
      "Epoch 221/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.8507\n",
      "Epoch 221: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7316666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4561 - accuracy: 0.8507 - val_loss: 0.9297 - val_accuracy: 0.7317\n",
      "Epoch 222/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8514\n",
      "Epoch 222: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4407 - accuracy: 0.8514 - val_loss: 0.9109 - val_accuracy: 0.7300\n",
      "Epoch 223/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.8536\n",
      "Epoch 223: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4251 - accuracy: 0.8536 - val_loss: 0.8957 - val_accuracy: 0.7417\n",
      "Epoch 224/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.8650\n",
      "Epoch 224: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4174 - accuracy: 0.8650 - val_loss: 0.9224 - val_accuracy: 0.7417\n",
      "Epoch 225/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8393\n",
      "Epoch 225: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7466666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4592 - accuracy: 0.8393 - val_loss: 0.8984 - val_accuracy: 0.7467\n",
      "Epoch 226/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.8493\n",
      "Epoch 226: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.74\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4452 - accuracy: 0.8493 - val_loss: 0.9540 - val_accuracy: 0.7400\n",
      "Epoch 227/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8721\n",
      "Epoch 227: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4012 - accuracy: 0.8721 - val_loss: 0.9316 - val_accuracy: 0.7450\n",
      "Epoch 228/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.8571\n",
      "Epoch 228: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4349 - accuracy: 0.8571 - val_loss: 0.9393 - val_accuracy: 0.7367\n",
      "Epoch 229/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8579\n",
      "Epoch 229: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4126 - accuracy: 0.8579 - val_loss: 0.9371 - val_accuracy: 0.7417\n",
      "Epoch 230/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8621\n",
      "Epoch 230: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4206 - accuracy: 0.8621 - val_loss: 0.9603 - val_accuracy: 0.7333\n",
      "Epoch 231/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.8393\n",
      "Epoch 231: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7433333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4328 - accuracy: 0.8393 - val_loss: 0.9386 - val_accuracy: 0.7433\n",
      "Epoch 232/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8757\n",
      "Epoch 232: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4020 - accuracy: 0.8757 - val_loss: 0.9358 - val_accuracy: 0.7333\n",
      "Epoch 233/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8664\n",
      "Epoch 233: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7333333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4235 - accuracy: 0.8664 - val_loss: 0.9732 - val_accuracy: 0.7333\n",
      "Epoch 234/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8571\n",
      "Epoch 234: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7466666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4250 - accuracy: 0.8571 - val_loss: 0.9006 - val_accuracy: 0.7467\n",
      "Epoch 235/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8664\n",
      "Epoch 235: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.735\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4164 - accuracy: 0.8664 - val_loss: 0.9686 - val_accuracy: 0.7350\n",
      "Epoch 236/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8543\n",
      "Epoch 236: val_accuracy did not improve from 0.75333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4281 - accuracy: 0.8543 - val_loss: 0.9206 - val_accuracy: 0.7367\n",
      "Epoch 237/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8607\n",
      "Epoch 237: val_accuracy improved from 0.75333 to 0.76000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4080 - accuracy: 0.8607 - val_loss: 0.8982 - val_accuracy: 0.7600\n",
      "Epoch 238/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8643\n",
      "Epoch 238: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3952 - accuracy: 0.8643 - val_loss: 0.9188 - val_accuracy: 0.7550\n",
      "Epoch 239/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8686\n",
      "Epoch 239: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3952 - accuracy: 0.8686 - val_loss: 0.9179 - val_accuracy: 0.7500\n",
      "Epoch 240/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8629\n",
      "Epoch 240: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7516666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4252 - accuracy: 0.8629 - val_loss: 0.9119 - val_accuracy: 0.7517\n",
      "Epoch 241/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8479\n",
      "Epoch 241: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4161 - accuracy: 0.8479 - val_loss: 0.9106 - val_accuracy: 0.7367\n",
      "Epoch 242/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.8614\n",
      "Epoch 242: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7100000000000001\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4254 - accuracy: 0.8614 - val_loss: 1.0037 - val_accuracy: 0.7100\n",
      "Epoch 243/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8457\n",
      "Epoch 243: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.735\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4533 - accuracy: 0.8457 - val_loss: 0.9399 - val_accuracy: 0.7350\n",
      "Epoch 244/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8429\n",
      "Epoch 244: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4246 - accuracy: 0.8429 - val_loss: 0.9182 - val_accuracy: 0.7550\n",
      "Epoch 245/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.8543\n",
      "Epoch 245: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4203 - accuracy: 0.8543 - val_loss: 0.9121 - val_accuracy: 0.7583\n",
      "Epoch 246/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.8586\n",
      "Epoch 246: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7466666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4219 - accuracy: 0.8586 - val_loss: 0.9385 - val_accuracy: 0.7467\n",
      "Epoch 247/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8657\n",
      "Epoch 247: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4229 - accuracy: 0.8657 - val_loss: 0.9186 - val_accuracy: 0.7583\n",
      "Epoch 248/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8643\n",
      "Epoch 248: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4002 - accuracy: 0.8643 - val_loss: 0.9160 - val_accuracy: 0.7450\n",
      "Epoch 249/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.8571\n",
      "Epoch 249: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4062 - accuracy: 0.8571 - val_loss: 0.9034 - val_accuracy: 0.7550\n",
      "Epoch 250/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.8629\n",
      "Epoch 250: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7433333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4015 - accuracy: 0.8629 - val_loss: 0.9260 - val_accuracy: 0.7433\n",
      "Epoch 251/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8750\n",
      "Epoch 251: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3732 - accuracy: 0.8750 - val_loss: 0.8991 - val_accuracy: 0.7500\n",
      "Epoch 252/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.8650\n",
      "Epoch 252: val_accuracy did not improve from 0.76000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4043 - accuracy: 0.8650 - val_loss: 0.9515 - val_accuracy: 0.7450\n",
      "Epoch 253/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8593\n",
      "Epoch 253: val_accuracy improved from 0.76000 to 0.76500, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3923 - accuracy: 0.8593 - val_loss: 0.9000 - val_accuracy: 0.7650\n",
      "Epoch 254/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.8564\n",
      "Epoch 254: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7433333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3986 - accuracy: 0.8564 - val_loss: 0.9397 - val_accuracy: 0.7433\n",
      "Epoch 255/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8814\n",
      "Epoch 255: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3824 - accuracy: 0.8814 - val_loss: 0.9096 - val_accuracy: 0.7417\n",
      "Epoch 256/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8671\n",
      "Epoch 256: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3824 - accuracy: 0.8671 - val_loss: 0.8940 - val_accuracy: 0.7550\n",
      "Epoch 257/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8700\n",
      "Epoch 257: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7466666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3606 - accuracy: 0.8700 - val_loss: 0.9492 - val_accuracy: 0.7467\n",
      "Epoch 258/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8707\n",
      "Epoch 258: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3777 - accuracy: 0.8707 - val_loss: 0.9213 - val_accuracy: 0.7450\n",
      "Epoch 259/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8657\n",
      "Epoch 259: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3866 - accuracy: 0.8657 - val_loss: 0.8945 - val_accuracy: 0.7500\n",
      "Epoch 260/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.8643\n",
      "Epoch 260: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7516666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3698 - accuracy: 0.8643 - val_loss: 0.9040 - val_accuracy: 0.7517\n",
      "Epoch 261/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8807\n",
      "Epoch 261: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3651 - accuracy: 0.8807 - val_loss: 0.9164 - val_accuracy: 0.7633\n",
      "Epoch 262/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8779\n",
      "Epoch 262: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3664 - accuracy: 0.8779 - val_loss: 0.8805 - val_accuracy: 0.7600\n",
      "Epoch 263/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8807\n",
      "Epoch 263: val_accuracy did not improve from 0.76500\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3473 - accuracy: 0.8807 - val_loss: 0.8668 - val_accuracy: 0.7633\n",
      "Epoch 264/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8693\n",
      "Epoch 264: val_accuracy improved from 0.76500 to 0.77000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3712 - accuracy: 0.8693 - val_loss: 0.8776 - val_accuracy: 0.7700\n",
      "Epoch 265/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.8757\n",
      "Epoch 265: val_accuracy did not improve from 0.77000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7433333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3710 - accuracy: 0.8757 - val_loss: 0.9017 - val_accuracy: 0.7433\n",
      "Epoch 266/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8800\n",
      "Epoch 266: val_accuracy did not improve from 0.77000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7483333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3831 - accuracy: 0.8800 - val_loss: 0.9285 - val_accuracy: 0.7483\n",
      "Epoch 267/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8693\n",
      "Epoch 267: val_accuracy did not improve from 0.77000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3790 - accuracy: 0.8693 - val_loss: 0.9356 - val_accuracy: 0.7533\n",
      "Epoch 268/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8621\n",
      "Epoch 268: val_accuracy did not improve from 0.77000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7566666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3840 - accuracy: 0.8621 - val_loss: 0.9031 - val_accuracy: 0.7567\n",
      "Epoch 269/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8821\n",
      "Epoch 269: val_accuracy did not improve from 0.77000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.74\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3497 - accuracy: 0.8821 - val_loss: 0.9571 - val_accuracy: 0.7400\n",
      "Epoch 270/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8679\n",
      "Epoch 270: val_accuracy improved from 0.77000 to 0.77167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3728 - accuracy: 0.8679 - val_loss: 0.8774 - val_accuracy: 0.7717\n",
      "Epoch 271/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8729\n",
      "Epoch 271: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3763 - accuracy: 0.8729 - val_loss: 0.9578 - val_accuracy: 0.7300\n",
      "Epoch 272/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8543\n",
      "Epoch 272: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4056 - accuracy: 0.8543 - val_loss: 0.9177 - val_accuracy: 0.7583\n",
      "Epoch 273/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8721\n",
      "Epoch 273: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3689 - accuracy: 0.8721 - val_loss: 0.9058 - val_accuracy: 0.7617\n",
      "Epoch 274/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8743\n",
      "Epoch 274: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.3588 - accuracy: 0.8743 - val_loss: 0.8982 - val_accuracy: 0.7633\n",
      "Epoch 275/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8871\n",
      "Epoch 275: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7433333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3505 - accuracy: 0.8871 - val_loss: 0.9376 - val_accuracy: 0.7433\n",
      "Epoch 276/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8779\n",
      "Epoch 276: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3570 - accuracy: 0.8779 - val_loss: 0.8817 - val_accuracy: 0.7633\n",
      "Epoch 277/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8871\n",
      "Epoch 277: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3417 - accuracy: 0.8871 - val_loss: 0.9125 - val_accuracy: 0.7667\n",
      "Epoch 278/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.8750\n",
      "Epoch 278: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7416666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3750 - accuracy: 0.8750 - val_loss: 0.9574 - val_accuracy: 0.7417\n",
      "Epoch 279/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8829\n",
      "Epoch 279: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3513 - accuracy: 0.8829 - val_loss: 0.8862 - val_accuracy: 0.7650\n",
      "Epoch 280/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8750\n",
      "Epoch 280: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3567 - accuracy: 0.8750 - val_loss: 0.9232 - val_accuracy: 0.7550\n",
      "Epoch 281/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8793\n",
      "Epoch 281: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3634 - accuracy: 0.8793 - val_loss: 0.8999 - val_accuracy: 0.7533\n",
      "Epoch 282/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8886\n",
      "Epoch 282: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3339 - accuracy: 0.8886 - val_loss: 0.8803 - val_accuracy: 0.7633\n",
      "Epoch 283/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.9007\n",
      "Epoch 283: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3177 - accuracy: 0.9007 - val_loss: 0.8812 - val_accuracy: 0.7667\n",
      "Epoch 284/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8893\n",
      "Epoch 284: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3386 - accuracy: 0.8893 - val_loss: 0.9085 - val_accuracy: 0.7633\n",
      "Epoch 285/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8821\n",
      "Epoch 285: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3504 - accuracy: 0.8821 - val_loss: 0.8763 - val_accuracy: 0.7600\n",
      "Epoch 286/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.8886\n",
      "Epoch 286: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3334 - accuracy: 0.8886 - val_loss: 0.9405 - val_accuracy: 0.7550\n",
      "Epoch 287/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8757\n",
      "Epoch 287: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3682 - accuracy: 0.8757 - val_loss: 0.9351 - val_accuracy: 0.7500\n",
      "Epoch 288/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.8214\n",
      "Epoch 288: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7366666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4722 - accuracy: 0.8214 - val_loss: 0.9298 - val_accuracy: 0.7367\n",
      "Epoch 289/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.4312 - accuracy: 0.8445\n",
      "Epoch 289: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7466666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4336 - accuracy: 0.8407 - val_loss: 0.9552 - val_accuracy: 0.7467\n",
      "Epoch 290/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.3997 - accuracy: 0.8571\n",
      "Epoch 290: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4007 - accuracy: 0.8579 - val_loss: 0.9321 - val_accuracy: 0.7550\n",
      "Epoch 291/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8557\n",
      "Epoch 291: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3916 - accuracy: 0.8557 - val_loss: 0.9749 - val_accuracy: 0.7500\n",
      "Epoch 292/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8679\n",
      "Epoch 292: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7566666666666667\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3846 - accuracy: 0.8679 - val_loss: 0.9530 - val_accuracy: 0.7567\n",
      "Epoch 293/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.8750\n",
      "Epoch 293: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3674 - accuracy: 0.8750 - val_loss: 0.9090 - val_accuracy: 0.7600\n",
      "Epoch 294/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8800\n",
      "Epoch 294: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3658 - accuracy: 0.8800 - val_loss: 0.9628 - val_accuracy: 0.7533\n",
      "Epoch 295/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8736\n",
      "Epoch 295: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3689 - accuracy: 0.8736 - val_loss: 0.9307 - val_accuracy: 0.7617\n",
      "Epoch 296/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8771\n",
      "Epoch 296: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3524 - accuracy: 0.8771 - val_loss: 0.8799 - val_accuracy: 0.7717\n",
      "Epoch 297/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8907\n",
      "Epoch 297: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3300 - accuracy: 0.8907 - val_loss: 0.9319 - val_accuracy: 0.7600\n",
      "Epoch 298/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.9000\n",
      "Epoch 298: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3160 - accuracy: 0.9000 - val_loss: 0.9573 - val_accuracy: 0.7633\n",
      "Epoch 299/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8821\n",
      "Epoch 299: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3373 - accuracy: 0.8821 - val_loss: 0.9200 - val_accuracy: 0.7600\n",
      "Epoch 300/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8721\n",
      "Epoch 300: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3596 - accuracy: 0.8721 - val_loss: 0.9167 - val_accuracy: 0.7650\n",
      "Epoch 301/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8757\n",
      "Epoch 301: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3394 - accuracy: 0.8757 - val_loss: 0.9038 - val_accuracy: 0.7533\n",
      "Epoch 302/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8836\n",
      "Epoch 302: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3328 - accuracy: 0.8836 - val_loss: 0.8730 - val_accuracy: 0.7683\n",
      "Epoch 303/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8900\n",
      "Epoch 303: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7516666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3270 - accuracy: 0.8900 - val_loss: 0.9535 - val_accuracy: 0.7517\n",
      "Epoch 304/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8757\n",
      "Epoch 304: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3586 - accuracy: 0.8757 - val_loss: 0.9099 - val_accuracy: 0.7550\n",
      "Epoch 305/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8871\n",
      "Epoch 305: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3090 - accuracy: 0.8871 - val_loss: 0.8893 - val_accuracy: 0.7650\n",
      "Epoch 306/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8864\n",
      "Epoch 306: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3270 - accuracy: 0.8864 - val_loss: 0.9145 - val_accuracy: 0.7500\n",
      "Epoch 307/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8864\n",
      "Epoch 307: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3156 - accuracy: 0.8864 - val_loss: 0.8959 - val_accuracy: 0.7600\n",
      "Epoch 308/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.8879\n",
      "Epoch 308: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3243 - accuracy: 0.8879 - val_loss: 0.9041 - val_accuracy: 0.7683\n",
      "Epoch 309/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8821\n",
      "Epoch 309: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3335 - accuracy: 0.8821 - val_loss: 0.9165 - val_accuracy: 0.7600\n",
      "Epoch 310/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8929\n",
      "Epoch 310: val_accuracy did not improve from 0.77167\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3287 - accuracy: 0.8929 - val_loss: 0.8853 - val_accuracy: 0.7683\n",
      "Epoch 311/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8971\n",
      "Epoch 311: val_accuracy improved from 0.77167 to 0.78333, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3059 - accuracy: 0.8971 - val_loss: 0.8740 - val_accuracy: 0.7833\n",
      "Epoch 312/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8950\n",
      "Epoch 312: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 12ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.3118 - accuracy: 0.8950 - val_loss: 0.9550 - val_accuracy: 0.7617\n",
      "Epoch 313/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.3186 - accuracy: 0.8906\n",
      "Epoch 313: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 1s 69ms/step - loss: 0.3189 - accuracy: 0.8907 - val_loss: 0.9226 - val_accuracy: 0.7667\n",
      "Epoch 314/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.3161 - accuracy: 0.8951\n",
      "Epoch 314: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3151 - accuracy: 0.8957 - val_loss: 0.9490 - val_accuracy: 0.7683\n",
      "Epoch 315/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8721\n",
      "Epoch 315: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.3512 - accuracy: 0.8721 - val_loss: 0.9435 - val_accuracy: 0.7683\n",
      "Epoch 316/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8907\n",
      "Epoch 316: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.3319 - accuracy: 0.8907 - val_loss: 0.9860 - val_accuracy: 0.7600\n",
      "Epoch 317/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8779\n",
      "Epoch 317: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3386 - accuracy: 0.8779 - val_loss: 0.9490 - val_accuracy: 0.7750\n",
      "Epoch 318/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.8921\n",
      "Epoch 318: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3115 - accuracy: 0.8921 - val_loss: 0.9768 - val_accuracy: 0.7550\n",
      "Epoch 319/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8886\n",
      "Epoch 319: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3177 - accuracy: 0.8886 - val_loss: 0.9179 - val_accuracy: 0.7783\n",
      "Epoch 320/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.9093\n",
      "Epoch 320: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.2847 - accuracy: 0.9093 - val_loss: 0.9330 - val_accuracy: 0.7733\n",
      "Epoch 321/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8993\n",
      "Epoch 321: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2950 - accuracy: 0.8993 - val_loss: 0.9090 - val_accuracy: 0.7800\n",
      "Epoch 322/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.2893 - accuracy: 0.9077\n",
      "Epoch 322: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2951 - accuracy: 0.9057 - val_loss: 0.9446 - val_accuracy: 0.7550\n",
      "Epoch 323/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8850\n",
      "Epoch 323: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.3059 - accuracy: 0.8850 - val_loss: 0.9162 - val_accuracy: 0.7783\n",
      "Epoch 324/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8814\n",
      "Epoch 324: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7483333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3207 - accuracy: 0.8814 - val_loss: 0.9698 - val_accuracy: 0.7483\n",
      "Epoch 325/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8750\n",
      "Epoch 325: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3402 - accuracy: 0.8750 - val_loss: 0.9071 - val_accuracy: 0.7650\n",
      "Epoch 326/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.8850\n",
      "Epoch 326: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3070 - accuracy: 0.8850 - val_loss: 0.9252 - val_accuracy: 0.7717\n",
      "Epoch 327/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8871\n",
      "Epoch 327: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3197 - accuracy: 0.8871 - val_loss: 0.8800 - val_accuracy: 0.7733\n",
      "Epoch 328/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9000\n",
      "Epoch 328: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2869 - accuracy: 0.9000 - val_loss: 0.9083 - val_accuracy: 0.7750\n",
      "Epoch 329/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8950\n",
      "Epoch 329: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2999 - accuracy: 0.8950 - val_loss: 0.9106 - val_accuracy: 0.7667\n",
      "Epoch 330/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8979\n",
      "Epoch 330: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2898 - accuracy: 0.8979 - val_loss: 0.9341 - val_accuracy: 0.7617\n",
      "Epoch 331/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.9057\n",
      "Epoch 331: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2820 - accuracy: 0.9057 - val_loss: 0.9155 - val_accuracy: 0.7633\n",
      "Epoch 332/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8886\n",
      "Epoch 332: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3042 - accuracy: 0.8886 - val_loss: 0.9113 - val_accuracy: 0.7717\n",
      "Epoch 333/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.9114\n",
      "Epoch 333: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2844 - accuracy: 0.9114 - val_loss: 0.9021 - val_accuracy: 0.7617\n",
      "Epoch 334/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8929\n",
      "Epoch 334: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7383333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3165 - accuracy: 0.8929 - val_loss: 0.9679 - val_accuracy: 0.7383\n",
      "Epoch 335/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.8836\n",
      "Epoch 335: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.76\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3397 - accuracy: 0.8836 - val_loss: 0.9222 - val_accuracy: 0.7600\n",
      "Epoch 336/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.8729\n",
      "Epoch 336: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3531 - accuracy: 0.8729 - val_loss: 0.9211 - val_accuracy: 0.7650\n",
      "Epoch 337/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8850\n",
      "Epoch 337: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3249 - accuracy: 0.8850 - val_loss: 0.9223 - val_accuracy: 0.7633\n",
      "Epoch 338/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8814\n",
      "Epoch 338: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3312 - accuracy: 0.8814 - val_loss: 0.8783 - val_accuracy: 0.7617\n",
      "Epoch 339/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9064\n",
      "Epoch 339: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3064 - accuracy: 0.9064 - val_loss: 0.9220 - val_accuracy: 0.7650\n",
      "Epoch 340/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.9071\n",
      "Epoch 340: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2907 - accuracy: 0.9071 - val_loss: 0.9276 - val_accuracy: 0.7583\n",
      "Epoch 341/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.8964\n",
      "Epoch 341: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3145 - accuracy: 0.8964 - val_loss: 0.9533 - val_accuracy: 0.7500\n",
      "Epoch 342/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.8986\n",
      "Epoch 342: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7516666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3031 - accuracy: 0.8986 - val_loss: 0.9746 - val_accuracy: 0.7517\n",
      "Epoch 343/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8993\n",
      "Epoch 343: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3055 - accuracy: 0.8993 - val_loss: 0.9365 - val_accuracy: 0.7717\n",
      "Epoch 344/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.8936\n",
      "Epoch 344: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2957 - accuracy: 0.8936 - val_loss: 0.9466 - val_accuracy: 0.7667\n",
      "Epoch 345/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.9050\n",
      "Epoch 345: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2742 - accuracy: 0.9050 - val_loss: 0.8858 - val_accuracy: 0.7833\n",
      "Epoch 346/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.9000\n",
      "Epoch 346: val_accuracy did not improve from 0.78333\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2873 - accuracy: 0.9000 - val_loss: 0.9830 - val_accuracy: 0.7633\n",
      "Epoch 347/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9107\n",
      "Epoch 347: val_accuracy improved from 0.78333 to 0.79000, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.79\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2694 - accuracy: 0.9107 - val_loss: 0.8958 - val_accuracy: 0.7900\n",
      "Epoch 348/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9100\n",
      "Epoch 348: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2821 - accuracy: 0.9100 - val_loss: 0.9270 - val_accuracy: 0.7533\n",
      "Epoch 349/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8914\n",
      "Epoch 349: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3074 - accuracy: 0.8914 - val_loss: 0.9381 - val_accuracy: 0.7750\n",
      "Epoch 350/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.9014\n",
      "Epoch 350: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.2844 - accuracy: 0.9014 - val_loss: 0.9374 - val_accuracy: 0.7633\n",
      "Epoch 351/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.8950\n",
      "Epoch 351: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2998 - accuracy: 0.8950 - val_loss: 0.9592 - val_accuracy: 0.7583\n",
      "Epoch 352/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8893\n",
      "Epoch 352: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.3111 - accuracy: 0.8893 - val_loss: 0.9226 - val_accuracy: 0.7733\n",
      "Epoch 353/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9114\n",
      "Epoch 353: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2776 - accuracy: 0.9114 - val_loss: 0.8738 - val_accuracy: 0.7817\n",
      "Epoch 354/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.8957\n",
      "Epoch 354: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2853 - accuracy: 0.8957 - val_loss: 0.8864 - val_accuracy: 0.7717\n",
      "Epoch 355/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.9079\n",
      "Epoch 355: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.2646 - accuracy: 0.9079 - val_loss: 0.9471 - val_accuracy: 0.7633\n",
      "Epoch 356/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.8950\n",
      "Epoch 356: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2846 - accuracy: 0.8950 - val_loss: 0.8818 - val_accuracy: 0.7767\n",
      "Epoch 357/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8929\n",
      "Epoch 357: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2981 - accuracy: 0.8929 - val_loss: 0.9179 - val_accuracy: 0.7733\n",
      "Epoch 358/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8964\n",
      "Epoch 358: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7633333333333333\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3046 - accuracy: 0.8964 - val_loss: 0.9696 - val_accuracy: 0.7633\n",
      "Epoch 359/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8814\n",
      "Epoch 359: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3369 - accuracy: 0.8814 - val_loss: 0.9718 - val_accuracy: 0.7683\n",
      "Epoch 360/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8943\n",
      "Epoch 360: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7866666666666666\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2962 - accuracy: 0.8943 - val_loss: 0.9163 - val_accuracy: 0.7867\n",
      "Epoch 361/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.9021\n",
      "Epoch 361: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2798 - accuracy: 0.9021 - val_loss: 0.9340 - val_accuracy: 0.7783\n",
      "Epoch 362/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9029\n",
      "Epoch 362: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2756 - accuracy: 0.9029 - val_loss: 0.9275 - val_accuracy: 0.7817\n",
      "Epoch 363/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9100\n",
      "Epoch 363: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2730 - accuracy: 0.9100 - val_loss: 0.9499 - val_accuracy: 0.7617\n",
      "Epoch 364/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.9007\n",
      "Epoch 364: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.745\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2830 - accuracy: 0.9007 - val_loss: 1.0014 - val_accuracy: 0.7450\n",
      "Epoch 365/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9107\n",
      "Epoch 365: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2635 - accuracy: 0.9107 - val_loss: 0.9271 - val_accuracy: 0.7783\n",
      "Epoch 366/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9207\n",
      "Epoch 366: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.75\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2517 - accuracy: 0.9207 - val_loss: 1.0169 - val_accuracy: 0.7500\n",
      "Epoch 367/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8964\n",
      "Epoch 367: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3139 - accuracy: 0.8964 - val_loss: 0.9238 - val_accuracy: 0.7733\n",
      "Epoch 368/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.9086\n",
      "Epoch 368: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2742 - accuracy: 0.9086 - val_loss: 0.9326 - val_accuracy: 0.7750\n",
      "Epoch 369/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9057\n",
      "Epoch 369: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7616666666666667\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2721 - accuracy: 0.9057 - val_loss: 0.9902 - val_accuracy: 0.7617\n",
      "Epoch 370/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.8993\n",
      "Epoch 370: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2919 - accuracy: 0.8993 - val_loss: 0.9646 - val_accuracy: 0.7683\n",
      "Epoch 371/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9093\n",
      "Epoch 371: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2596 - accuracy: 0.9093 - val_loss: 0.8811 - val_accuracy: 0.7833\n",
      "Epoch 372/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.9207\n",
      "Epoch 372: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2432 - accuracy: 0.9207 - val_loss: 0.8901 - val_accuracy: 0.7783\n",
      "Epoch 373/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9164\n",
      "Epoch 373: val_accuracy did not improve from 0.79000\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2549 - accuracy: 0.9164 - val_loss: 0.8970 - val_accuracy: 0.7800\n",
      "Epoch 374/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.9150\n",
      "Epoch 374: val_accuracy improved from 0.79000 to 0.79833, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7983333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2494 - accuracy: 0.9150 - val_loss: 0.8972 - val_accuracy: 0.7983\n",
      "Epoch 375/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.9186\n",
      "Epoch 375: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.765\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2483 - accuracy: 0.9186 - val_loss: 0.9982 - val_accuracy: 0.7650\n",
      "Epoch 376/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9093\n",
      "Epoch 376: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2577 - accuracy: 0.9093 - val_loss: 0.9559 - val_accuracy: 0.7717\n",
      "Epoch 377/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9200\n",
      "Epoch 377: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2525 - accuracy: 0.9200 - val_loss: 0.9157 - val_accuracy: 0.7817\n",
      "Epoch 378/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.9057\n",
      "Epoch 378: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7983333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2712 - accuracy: 0.9057 - val_loss: 0.9143 - val_accuracy: 0.7983\n",
      "Epoch 379/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9079\n",
      "Epoch 379: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2637 - accuracy: 0.9079 - val_loss: 0.9180 - val_accuracy: 0.7833\n",
      "Epoch 380/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9136\n",
      "Epoch 380: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7916666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2544 - accuracy: 0.9136 - val_loss: 0.9001 - val_accuracy: 0.7917\n",
      "Epoch 381/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9129\n",
      "Epoch 381: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2498 - accuracy: 0.9107 - val_loss: 0.9718 - val_accuracy: 0.7783\n",
      "Epoch 382/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.2514 - accuracy: 0.9137\n",
      "Epoch 382: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2570 - accuracy: 0.9100 - val_loss: 0.9194 - val_accuracy: 0.7733\n",
      "Epoch 383/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.9214\n",
      "Epoch 383: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.79\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2537 - accuracy: 0.9214 - val_loss: 0.9373 - val_accuracy: 0.7900\n",
      "Epoch 384/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9114\n",
      "Epoch 384: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2548 - accuracy: 0.9114 - val_loss: 0.9325 - val_accuracy: 0.7783\n",
      "Epoch 385/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9029\n",
      "Epoch 385: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2721 - accuracy: 0.9029 - val_loss: 0.9784 - val_accuracy: 0.7700\n",
      "Epoch 386/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.9179\n",
      "Epoch 386: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2515 - accuracy: 0.9179 - val_loss: 0.9553 - val_accuracy: 0.7700\n",
      "Epoch 387/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9136\n",
      "Epoch 387: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.2541 - accuracy: 0.9136 - val_loss: 0.9458 - val_accuracy: 0.7783\n",
      "Epoch 388/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9179\n",
      "Epoch 388: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2578 - accuracy: 0.9179 - val_loss: 0.9355 - val_accuracy: 0.7767\n",
      "Epoch 389/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.9036\n",
      "Epoch 389: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7866666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2801 - accuracy: 0.9036 - val_loss: 0.9833 - val_accuracy: 0.7867\n",
      "Epoch 390/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8979\n",
      "Epoch 390: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7866666666666666\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2934 - accuracy: 0.8979 - val_loss: 0.9426 - val_accuracy: 0.7867\n",
      "Epoch 391/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9043\n",
      "Epoch 391: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2750 - accuracy: 0.9043 - val_loss: 0.9613 - val_accuracy: 0.7817\n",
      "Epoch 392/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.9150\n",
      "Epoch 392: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2485 - accuracy: 0.9150 - val_loss: 0.9301 - val_accuracy: 0.7800\n",
      "Epoch 393/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.9193\n",
      "Epoch 393: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2407 - accuracy: 0.9193 - val_loss: 0.9161 - val_accuracy: 0.7800\n",
      "Epoch 394/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9050\n",
      "Epoch 394: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2593 - accuracy: 0.9050 - val_loss: 0.9220 - val_accuracy: 0.7800\n",
      "Epoch 395/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.9057\n",
      "Epoch 395: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2701 - accuracy: 0.9057 - val_loss: 0.9602 - val_accuracy: 0.7733\n",
      "Epoch 396/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9021\n",
      "Epoch 396: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2694 - accuracy: 0.9021 - val_loss: 1.0269 - val_accuracy: 0.7550\n",
      "Epoch 397/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9136\n",
      "Epoch 397: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2623 - accuracy: 0.9136 - val_loss: 0.9321 - val_accuracy: 0.7750\n",
      "Epoch 398/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2524 - accuracy: 0.9086\n",
      "Epoch 398: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2524 - accuracy: 0.9086 - val_loss: 0.9325 - val_accuracy: 0.7833\n",
      "Epoch 399/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.9179\n",
      "Epoch 399: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7916666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2439 - accuracy: 0.9179 - val_loss: 0.9625 - val_accuracy: 0.7917\n",
      "Epoch 400/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9079\n",
      "Epoch 400: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2710 - accuracy: 0.9079 - val_loss: 0.9632 - val_accuracy: 0.7683\n",
      "Epoch 401/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9171\n",
      "Epoch 401: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2398 - accuracy: 0.9171 - val_loss: 0.9540 - val_accuracy: 0.7717\n",
      "Epoch 402/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9229\n",
      "Epoch 402: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2292 - accuracy: 0.9229 - val_loss: 0.9667 - val_accuracy: 0.7683\n",
      "Epoch 403/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9121\n",
      "Epoch 403: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2500 - accuracy: 0.9121 - val_loss: 0.9820 - val_accuracy: 0.7783\n",
      "Epoch 404/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9250\n",
      "Epoch 404: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7783333333333333\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.9489 - val_accuracy: 0.7783\n",
      "Epoch 405/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9250\n",
      "Epoch 405: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.795\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2180 - accuracy: 0.9250 - val_loss: 0.9037 - val_accuracy: 0.7950\n",
      "Epoch 406/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9214\n",
      "Epoch 406: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.785\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2249 - accuracy: 0.9214 - val_loss: 0.9445 - val_accuracy: 0.7850\n",
      "Epoch 407/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9221\n",
      "Epoch 407: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2326 - accuracy: 0.9221 - val_loss: 0.9689 - val_accuracy: 0.7733\n",
      "Epoch 408/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9107\n",
      "Epoch 408: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2513 - accuracy: 0.9107 - val_loss: 0.9677 - val_accuracy: 0.7717\n",
      "Epoch 409/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.8986\n",
      "Epoch 409: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2688 - accuracy: 0.8986 - val_loss: 0.9890 - val_accuracy: 0.7733\n",
      "Epoch 410/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.8957\n",
      "Epoch 410: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 13ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.3061 - accuracy: 0.8957 - val_loss: 1.0013 - val_accuracy: 0.7700\n",
      "Epoch 411/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.9007\n",
      "Epoch 411: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2911 - accuracy: 0.9007 - val_loss: 0.9488 - val_accuracy: 0.7833\n",
      "Epoch 412/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9171\n",
      "Epoch 412: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7683333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2492 - accuracy: 0.9171 - val_loss: 0.9776 - val_accuracy: 0.7683\n",
      "Epoch 413/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9243\n",
      "Epoch 413: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2270 - accuracy: 0.9243 - val_loss: 0.9359 - val_accuracy: 0.7933\n",
      "Epoch 414/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.9214\n",
      "Epoch 414: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7716666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2439 - accuracy: 0.9214 - val_loss: 0.9722 - val_accuracy: 0.7717\n",
      "Epoch 415/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.9129\n",
      "Epoch 415: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7966666666666665\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2420 - accuracy: 0.9129 - val_loss: 0.9296 - val_accuracy: 0.7967\n",
      "Epoch 416/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9207\n",
      "Epoch 416: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2369 - accuracy: 0.9207 - val_loss: 0.9524 - val_accuracy: 0.7800\n",
      "Epoch 417/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.9107\n",
      "Epoch 417: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2374 - accuracy: 0.9107 - val_loss: 0.9743 - val_accuracy: 0.7700\n",
      "Epoch 418/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9171\n",
      "Epoch 418: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7833333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2328 - accuracy: 0.9171 - val_loss: 0.9562 - val_accuracy: 0.7833\n",
      "Epoch 419/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9143\n",
      "Epoch 419: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2415 - accuracy: 0.9143 - val_loss: 0.9681 - val_accuracy: 0.7767\n",
      "Epoch 420/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9179\n",
      "Epoch 420: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2461 - accuracy: 0.9179 - val_loss: 1.0039 - val_accuracy: 0.7767\n",
      "Epoch 421/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9236\n",
      "Epoch 421: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.795\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2333 - accuracy: 0.9236 - val_loss: 0.9521 - val_accuracy: 0.7950\n",
      "Epoch 422/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9200\n",
      "Epoch 422: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2276 - accuracy: 0.9200 - val_loss: 0.9533 - val_accuracy: 0.7933\n",
      "Epoch 423/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9250\n",
      "Epoch 423: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2408 - accuracy: 0.9250 - val_loss: 0.9842 - val_accuracy: 0.7667\n",
      "Epoch 424/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9214\n",
      "Epoch 424: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2379 - accuracy: 0.9214 - val_loss: 0.9690 - val_accuracy: 0.7800\n",
      "Epoch 425/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9314\n",
      "Epoch 425: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2163 - accuracy: 0.9314 - val_loss: 0.9663 - val_accuracy: 0.7933\n",
      "Epoch 426/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9307\n",
      "Epoch 426: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.795\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2171 - accuracy: 0.9307 - val_loss: 0.9230 - val_accuracy: 0.7950\n",
      "Epoch 427/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9271\n",
      "Epoch 427: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2324 - accuracy: 0.9271 - val_loss: 0.9871 - val_accuracy: 0.7667\n",
      "Epoch 428/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.9129\n",
      "Epoch 428: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2468 - accuracy: 0.9129 - val_loss: 0.9971 - val_accuracy: 0.7733\n",
      "Epoch 429/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9193\n",
      "Epoch 429: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2279 - accuracy: 0.9193 - val_loss: 0.9410 - val_accuracy: 0.7817\n",
      "Epoch 430/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.2439 - accuracy: 0.9122\n",
      "Epoch 430: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.2492 - accuracy: 0.9093 - val_loss: 0.9500 - val_accuracy: 0.7750\n",
      "Epoch 431/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9036\n",
      "Epoch 431: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.755\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2727 - accuracy: 0.9036 - val_loss: 1.0411 - val_accuracy: 0.7550\n",
      "Epoch 432/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9014\n",
      "Epoch 432: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2754 - accuracy: 0.9014 - val_loss: 0.9850 - val_accuracy: 0.7817\n",
      "Epoch 433/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.9164\n",
      "Epoch 433: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7816666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2505 - accuracy: 0.9164 - val_loss: 0.9426 - val_accuracy: 0.7817\n",
      "Epoch 434/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.9129\n",
      "Epoch 434: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.78\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2569 - accuracy: 0.9129 - val_loss: 0.9469 - val_accuracy: 0.7800\n",
      "Epoch 435/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9236\n",
      "Epoch 435: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.785\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2293 - accuracy: 0.9236 - val_loss: 0.9486 - val_accuracy: 0.7850\n",
      "Epoch 436/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9300\n",
      "Epoch 436: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7733333333333333\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.2169 - accuracy: 0.9300 - val_loss: 0.9455 - val_accuracy: 0.7733\n",
      "Epoch 437/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9186\n",
      "Epoch 437: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2298 - accuracy: 0.9186 - val_loss: 0.9206 - val_accuracy: 0.7933\n",
      "Epoch 438/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9200\n",
      "Epoch 438: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7666666666666667\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2216 - accuracy: 0.9200 - val_loss: 0.9601 - val_accuracy: 0.7667\n",
      "Epoch 439/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9214\n",
      "Epoch 439: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.785\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2386 - accuracy: 0.9214 - val_loss: 0.9700 - val_accuracy: 0.7850\n",
      "Epoch 440/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9143\n",
      "Epoch 440: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7583333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2508 - accuracy: 0.9143 - val_loss: 0.9945 - val_accuracy: 0.7583\n",
      "Epoch 441/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9243\n",
      "Epoch 441: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2188 - accuracy: 0.9243 - val_loss: 0.9201 - val_accuracy: 0.7933\n",
      "Epoch 442/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9250\n",
      "Epoch 442: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7883333333333333\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2209 - accuracy: 0.9250 - val_loss: 0.9782 - val_accuracy: 0.7883\n",
      "Epoch 443/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9393\n",
      "Epoch 443: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7533333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2119 - accuracy: 0.9393 - val_loss: 1.0710 - val_accuracy: 0.7533\n",
      "Epoch 444/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9171\n",
      "Epoch 444: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2303 - accuracy: 0.9171 - val_loss: 0.9922 - val_accuracy: 0.7767\n",
      "Epoch 445/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9343\n",
      "Epoch 445: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2149 - accuracy: 0.9343 - val_loss: 0.9513 - val_accuracy: 0.7767\n",
      "Epoch 446/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9364\n",
      "Epoch 446: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.785\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1980 - accuracy: 0.9364 - val_loss: 0.9421 - val_accuracy: 0.7850\n",
      "Epoch 447/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.9400\n",
      "Epoch 447: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.1958 - accuracy: 0.9400 - val_loss: 0.9135 - val_accuracy: 0.7933\n",
      "Epoch 448/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9250\n",
      "Epoch 448: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7933333333333333\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2285 - accuracy: 0.9250 - val_loss: 0.9379 - val_accuracy: 0.7933\n",
      "Epoch 449/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.9379\n",
      "Epoch 449: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7766666666666666\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2012 - accuracy: 0.9379 - val_loss: 0.9627 - val_accuracy: 0.7767\n",
      "Epoch 450/3000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9236\n",
      "Epoch 450: val_accuracy did not improve from 0.79833\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.775\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2220 - accuracy: 0.9236 - val_loss: 0.9811 - val_accuracy: 0.7750\n",
      "Epoch 451/3000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.2055 - accuracy: 0.9315\n",
      "Epoch 451: val_accuracy improved from 0.79833 to 0.80167, saving model to ./model2/best_model_2.h5\n",
      "19/19 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.8016666666666666\n",
      "\n",
      "Reached 0.80% val_F1_score, so stopping training!!\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.9703 - val_accuracy: 0.8017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f300c2798a0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "\n",
    "model2.fit([X_train_spectrogram],y_train_int, batch_size=64, epochs=3000, \n",
    "           validation_data=([X_test_spectrogram], y_test_int), callbacks=[callbacks2, metrics, tensorboard2],\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>At end of 451 epoch val_F1_score 0.80</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-769d723634a6f7ab\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-769d723634a6f7ab\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model2/model2_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f30341484f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation iou_score values\n",
    "import matplotlib.pyplot as plt\n",
    "his = pd.read_csv('model2/history.csv')\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['loss'])\n",
    "plt.plot(his['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "862fP2e-aNp3"
   },
   "source": [
    "> <b> From the above plot we can ensure that model is slightly gets overfit</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtMsbGs3aNp_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSl8ZOXjaNqJ"
   },
   "source": [
    "### 3. Data augmentation with raw features \n",
    "\n",
    "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
    "\n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "jR4JSEDgaNqK"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path,get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path     recordings/3_jackson_1.wav\n",
       "label                             3\n",
       "Name: 766, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "QRdefb-SaNqS"
   },
   "outputs": [],
   "source": [
    "temp_path = df_audio.iloc[0].path\n",
    "aug_temp = generate_augmented_data(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "kzdG3iS-aNqc",
    "outputId": "0f17e45e-63a0-4986-8f69-05e2dbd71bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckytZsraNqk"
   },
   "source": [
    "## Follow the steps \n",
    "\n",
    "1. Split data 'df_audio' into train and test (80-20 split)\n",
    "\n",
    "2. We have 2000 data points(1600 train points, 400 test points) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "LFo5SnTLO_sD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(df_audio['path'],df_audio['label'],random_state=45,test_size=0.2,stratify=df_audio['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdKXVRlpaNql"
   },
   "source": [
    "3. Do augmentation only on X_train,pass each point of X_train to generate_augmented_data function.After augmentation we will get 14400 train points. Make sure that you are augmenting the corresponding class labels (y_train) also.\n",
    "4. Preprocess your X_test using load_wav function.\n",
    "5. Convert the augmented_train_data and test_data to numpy arrays.\n",
    "6. Perform padding and masking on augmented_train_data and test_data.\n",
    "7. After padding define the model similar to model 1 and fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8Yh72uYO_sD"
   },
   "source": [
    "<font color='red'> Note </font> - While fitting your model on the augmented data for model 3 you might face Resource exhaust error. One simple hack to avoid that is save the augmented_train_data,augment_y_train,test_data and y_test to Drive or into your local system. Then restart the runtime so that now you can train your model with full RAM capacity. Upload these files again in the new runtime session perform padding and masking and then fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263     recordings/8_yweweler_4.wav\n",
       "142     recordings/2_yweweler_42.wav\n",
       "1954         recordings/7_theo_7.wav\n",
       "65          recordings/3_theo_46.wav\n",
       "1531     recordings/9_jackson_32.wav\n",
       "                    ...             \n",
       "113          recordings/9_theo_7.wav\n",
       "1637     recordings/7_jackson_22.wav\n",
       "1473      recordings/0_jackson_1.wav\n",
       "617      recordings/3_yweweler_3.wav\n",
       "1639     recordings/2_nicolas_22.wav\n",
       "Name: path, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263    8\n",
       "142     2\n",
       "1954    7\n",
       "65      3\n",
       "1531    9\n",
       "       ..\n",
       "113     9\n",
       "1637    7\n",
       "1473    0\n",
       "617     3\n",
       "1639    2\n",
       "Name: label, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1600/1600 [03:15<00:00,  8.16it/s]\n",
      "100%|███████████████████████████████████| 1600/1600 [00:00<00:00, 196730.96it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    temp_path = X_train.iloc[i]\n",
    "    X_train_aug.append(generate_augmented_data(temp_path))\n",
    "    \n",
    "for j in tqdm(range(len(y_train_int))):\n",
    "    temp_label = y_train_int.iloc[j]\n",
    "    y_train_aug.append([temp_label]*9)\n",
    "    \n",
    "X_train_aug = np.array(X_train_aug)\n",
    "y_train_aug = np.array(y_train_aug)\n",
    "\n",
    "X_train_augmented = X_train_aug.flatten()\n",
    "y_train_augmented = y_train_aug.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train_augmented, y_train_augmented),open('model3/augmented.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#X_train_augmented, y_train_augmented = pickle.load(open('model3/augmented.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(14400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_augmented.shape)\n",
    "print(y_train_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.7550347e-04  2.7281698e-04  1.2551129e-04 ... -1.2097165e-04\n",
      " -9.4063718e-05 -9.1231283e-05]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(X_train_augmented[9])\n",
    "print(y_train_augmented[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 400/400 [00:02<00:00, 136.74it/s]\n"
     ]
    }
   ],
   "source": [
    "X_te = X_test.values\n",
    "\n",
    "test_raw_data = []\n",
    "test_duration = []\n",
    "\n",
    "for i in tqdm(range(len(X_te))):\n",
    "    samples, duration = load_wav(X_te[i])\n",
    "    test_raw_data.append(samples)\n",
    "    test_duration.append(duration)\n",
    "    \n",
    "X_test_processed = pd.DataFrame()\n",
    "X_test_processed['raw_data'] = test_raw_data\n",
    "X_test_processed['duration'] = test_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-2.4109613e-05, 6.209989e-05, 0.0001363404, 0...</td>\n",
       "      <td>0.409388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.009577481, -0.011705862, -0.01152472, -0.0...</td>\n",
       "      <td>0.355782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.00021788295, -0.00023067498, -0.0001956816...</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.009968175, 0.007859625, 0.003288437, -0.000...</td>\n",
       "      <td>0.582902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.0071265, -0.0045903055, -0.0015180755, -0....</td>\n",
       "      <td>0.553651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [-2.4109613e-05, 6.209989e-05, 0.0001363404, 0...  0.409388\n",
       "1  [-0.009577481, -0.011705862, -0.01152472, -0.0...  0.355782\n",
       "2  [-0.00021788295, -0.00023067498, -0.0001956816...  0.326531\n",
       "3  [0.009968175, 0.007859625, 0.003288437, -0.000...  0.582902\n",
       "4  [-0.0071265, -0.0045903055, -0.0015180755, -0....  0.553651"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test_processed['raw_data'].values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5530"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_augmented[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 14400/14400 [00:16<00:00, 862.99it/s]\n",
      "100%|████████████████████████████████████████| 400/400 [00:00<00:00, 906.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 17640)\n",
      "(400, 17640)\n",
      "(14400, 17640)\n",
      "(400, 17640)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/30475558/padding-or-truncating-a-python-list\n",
    "\n",
    "def trp(l, n):\n",
    "    \"\"\" Truncate or pad a list \"\"\"\n",
    "    r = list(l[:n])\n",
    "    if(len(r) < n):\n",
    "        r.extend([0] * (n - len(r)))\n",
    "    return r\n",
    "\n",
    "X_train_pad_seq = []\n",
    "X_train_mask = []\n",
    "X_test_pad_seq = []\n",
    "X_test_mask = []\n",
    "\n",
    "for i in tqdm(range(len(X_train_augmented))):\n",
    "    pad_seq = trp(np.array(X_train_augmented[i]), max_length)\n",
    "    X_train_pad_seq.append(pad_seq)\n",
    "    \n",
    "    \n",
    "for i in tqdm(range(len(X_test))):\n",
    "    pad_seq = trp(np.array(X_test[i]), max_length)\n",
    "    X_test_pad_seq.append(pad_seq)\n",
    "    \n",
    "\n",
    "\n",
    "X_train_pad_seq = np.array(X_train_pad_seq)\n",
    "X_test_pad_seq = np.array(X_test_pad_seq)\n",
    "\n",
    "X_train_mask = np.where(X_train_pad_seq != 0, 1, 0)\n",
    "X_train_mask = X_train_mask.astype(bool)\n",
    "X_test_mask = np.where(X_test_pad_seq != 0, 1, 0)\n",
    "X_test_mask = X_test_mask.astype(bool)\n",
    "\n",
    "print(X_train_pad_seq.shape)\n",
    "print(X_test_pad_seq.shape)\n",
    "\n",
    "print(X_train_mask.shape)\n",
    "print(X_test_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " seq_inp (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " mask_inp (InputLayer)          [(None, 17640)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           16896       ['seq_inp[0][0]',                \n",
      "                                                                  'mask_inp[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           4160        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           650         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,706\n",
      "Trainable params: 21,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## as discussed above, please write the architecture of the model.\n",
    "## you will have two input layers in your model (data input layer and mask input layer)\n",
    "## make sure that you have defined the data type of masking layer as bool\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "seq_inp_layer = Input(shape=(17640,1), dtype='float32',name='seq_inp')\n",
    "mask_inp_layer = Input(shape=(17640), dtype='bool',name='mask_inp')\n",
    "lstm = LSTM(64)(seq_inp_layer,mask=mask_inp_layer)\n",
    "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(lstm)\n",
    "dp1 = Dropout(0.2)(fc1)\n",
    "out_layer = Dense(10,activation='softmax')(dp1)\n",
    "\n",
    "model3 = Model(inputs=[seq_inp_layer,mask_inp_layer],outputs=out_layer)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model3, to_file='model3/model3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.x_test = validation_data[0]\n",
    "        self.y_test = validation_data[1]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label = np.argmax(val_predict, axis = 1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label, average='micro')\n",
    "        print(\"val_F1_score: \", val_f1)\n",
    "        \n",
    "metrics = Metrics(validation_data=([X_test_pad_seq,X_test_mask], y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 18:14:59.085720: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-02 18:14:59.085747: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-02 18:14:59.085912: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-02 18:14:59.085922: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-02 18:14:59.085926: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-02 18:14:59.085931: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-02 18:14:59.086000: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-02 18:14:59.086031: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-02 18:14:59.086035: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-02 18:14:59.086038: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    }
   ],
   "source": [
    "tensorboard3 = TensorBoard(log_dir='model3/model3_logs'.format(time()), histogram_freq=1, write_graph=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks3 = [\n",
    "    ModelCheckpoint(filepath='./model3/best_model_3.h5', save_weights_only = True, save_best_only = True, \\\n",
    "                                       mode = 'max', monitor = 'val_accuracy', verbose = 1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', patience = 1, mode = 'max', verbose = 1),\n",
    "    tf.keras.callbacks.CSVLogger('./model3/history.csv'),\n",
    "]\n",
    "\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0006,decay = 1e-4),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/225 [..............................] - ETA: 34:18 - loss: 2.3026 - accuracy: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 18:15:22.732962: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-02 18:15:22.732994: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-02 18:15:22.733041: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-02 18:15:22.733050: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-02 18:15:22.733058: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-02 18:15:22.733063: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-02 18:15:30.677094: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-09-02 18:15:30.835014: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-02 18:15:30.835051: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-02 18:15:30.835056: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-09-02 18:15:36.047919: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-02 18:15:36.047957: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-02 18:15:36.047963: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-09-02 18:15:42.203276: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-02 18:15:49.864184: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42\n",
      "\n",
      "2022-09-02 18:15:52.450548: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.trace.json.gz\n",
      "2022-09-02 18:15:59.497667: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42\n",
      "\n",
      "2022-09-02 18:15:59.503822: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.memory_profile.json.gz\n",
      "2022-09-02 18:15:59.599289: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42\n",
      "Dumped tool data for xplane.pb to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model3/model3_logs/train/plugins/profile/2022_09_02_18_15_42/AI-iiitg.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - ETA: 0s - loss: 2.3029 - accuracy: 0.0988\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to ./model3/best_model_3.h5\n",
      "13/13 [==============================] - 24s 2s/step\n",
      "val_F1_score:  0.10000000000000002\n",
      "225/225 [==============================] - 1932s 9s/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 6.0000e-04\n",
      "Epoch 2/2\n",
      "225/225 [==============================] - ETA: 0s - loss: 2.3028 - accuracy: 0.0955\n",
      "Epoch 2: val_accuracy did not improve from 0.10000\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 6.000000284984708e-05.\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "val_F1_score:  0.10000000000000002\n",
      "225/225 [==============================] - 1894s 8s/step - loss: 2.3028 - accuracy: 0.0955 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 6.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe76557d300>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "model3.fit([X_train_pad_seq,X_train_mask],y_train_augmented, batch_size=64, epochs=2, \n",
    "           validation_data=([X_test_pad_seq,X_test_mask], y_test_int), callbacks=[callbacks3, metrics, tensorboard3],\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>At end of 2 epoch val_F1_score 0.10</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5de32c2c7c38b006\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5de32c2c7c38b006\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model3/model3_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe75c603640>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAFNCAYAAADPS8TxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9ZklEQVR4nO3de5Scd33n+fe3793qllp3S2rfAJlggjGmYxMWEi4LYztk5DkDAWKwAe94zS65wMmAJ5nZZCaZjbOzYRITj70OY8DDLRyYrJXl4hgPBhJsbJkYg2yMhfClZVn31rVb6m5994962q6urm6VZFXf6v06p05VPb/n99Tvseu0+tPP7/t7IjORJEmSpEbVNNsDkCRJkqTZZCiSJEmS1NAMRZIkSZIamqFIkiRJUkMzFEmSJElqaIYiSZIkSQ3NUCRJWrAi4pyIyIhoqWHf90XEP7zQ40iS5h9DkSRpToiIJyLiWESsqNj+UBFIzpmloUmSFjhDkSRpLvk58O7xNxHxCqBz9oYjSWoEhiJJ0lzy34Cryt5fDdxevkNELImI2yNiV0Q8GRH/NiKairbmiPi/I2J3RGwFfq1K3/8aEdsjYltE/ElENJ/sICNibURsjIi9EbElIv5VWdvFEbEpIg5ExI6I+HixvSMiPhsReyJiMCIeiIjVJ/vZkqTTz1AkSZpL7gMWR8TLirDyTuCzFft8AlgCvAj4VUoh6v1F278C3ga8CugH3l7R9zPAKPCSYp+3Av/LKYzzC8AAsLb4jP8zIt5ctP0l8JeZuRh4MfClYvvVxbjPBJYD1wFDp/DZkqTTzFB0iiLiP0XETyLi4Yj424jorbJPR0TcHxE/jIjNEfHvy9qWRcRdEfF48by02P6WiHgwIn5UPL+prM+ri+1bIuLGiIhie3tE/E2x/fvl8+4j4uriMx6PiKvLtp9b7Pt40bet2B7FsbcU53ZRWZ9LI+Kxou36E52LJJ2i8atFbwF+AmwbbygLSv8mMw9m5hPAnwPvLXb5DeAvMvPpzNwL/GlZ39XAZcDvZubhzNwJ/GfgXSczuIg4E3gd8LHMHM7Mh4BPlo1hBHhJRKzIzEOZeV/Z9uXASzJzLDMfzMwDJ/PZkqT6MBTVICLeEBGfrth8F/CLmXkB8FPg31TpehR4U2a+ErgQuDQiXlO0XQ/cnZnrgbuL9wC7gV/PzFdQ+qvifys73s3AtcD64nFpsf0aYF9mvoTSP/B/Vox7GfCHwCXAxcAflgWWPwP+c/H5+4pjQOkXhvHjX1t85vgvIjcV7ecD746I809wLpJ0Kv4b8JvA+6iYOgesANqAJ8u2PQmsK16vBZ6uaBt3NtAKbC+mrw0C/w+w6iTHtxbYm5kHpxjDNcB5wE+KKXJvKzuvO4EvRsQzEfF/RUTrSX62JKkODEWnKDP/PjNHi7f3AX1V9snMPFS8bS0eWbzfQGkaB8XzFUWff8rMZ4rtm4GO4krQGmBxZt6bmUnpF4Urqhzry8Cbi6tI/wy4KzP3ZuY+SkHu0qLtTcW+Ez6/ONbtxdjvA3qLz74Y2JKZWzPzGPDFYt8pz0WSTkVmPklpwYXLgf9e0byb0hWXs8u2ncXzV5O2U5qeVt427mlKf6xakZm9xWNxZr78JIf4DLAsInqqjSEzH8/Md1MKW38GfDkiFmXmSGb++8w8H3gtpWl+VyFJmnWGotPjA8DXqzUURb8PATspBZTvF02rM3M7QPFc7S+V/xL4p8w8SukvkANlbQM8/1fJdRR/GS2C2n5KUzSe217RZzkwWBbqqh6rom2q7bWeiySdjGsoXWk/XL4xM8co1ej8x4joiYizgY/wfN3Rl4Dfjoi+4sr49WV9twN/D/x5RCyOiKaIeHFE/OrJDCwznwa+B/xpMU36gmK8nwOIiPdExMrMPA4MFt3GIuKNEfGK4sr7AUrhbuxkPluSVB+GomkUNTcPUZor/s+jdK+MhyLin5Xt8weUinY/V+0YxbzxCyldSbo4In6xxs9+OaW/MP6v45uqHf4EbSe7/VSOJUmnXWb+LDM3TdH8W8BhYCvwD8DngduKtr+mNEXth8APmHyl6SpK0+8eoTR1+MvAmlMY4ruBcyhdNfpb4A8z866i7VJgc0QcorTowrsycxg4o/i8A8CjwLeZvIiEJGkWeGfuaWTmJVCqKQLel5nvK28vFi54G/DmYkrbdMcajIh7KP1j+WNgR0SsycztxfS0nWXH7aP0j+xVmfmzYvMAE6fo9VH6x3i87UxgIEp3W18C7C22v6Gizz2Upp/0RkRLcbWo2rEqP6dtiu1Mdy6SVKvMPGeK7aOU/WGmmA78nmn2/XDxGHdTWft+4IPFo7Lvp4FPT3HcJyrGMEDp53+1faca2xcorVonSZpjvFJ0iiLiUuBjwD/PzCNT7LNyfFW6iOgE/mdKKykBbKS0kALF8x3Ffr3AVymtrPSP48cqpn0cjIjXFDVBV433qTjW24H/UYS0O4G3RsTSYhrJW4E7i7Zv8fxStVdXHOuqYhW61wD7i89+AFhfrFrXRmm1po3TnYskSZI0H8QJLnCI6leKImIL0A7sKTbdl5nXRcRa4JOZeXkxz/wzQDOlAPqlzPwPRf/llOa+nwU8BbwjM/dGxL+ltJLd42VDeGtm7oyIfkp/xeykVMP0W5mZEdFBaVWjV1G6QvSuzNxafM4HgN8vjvMfM/NTxfYXUVosYRnwT8B7MvNoEbj+itIVrSPA+8ensETE5cBfFOdzW2b+x+nO5VT+W0uSJEkzzVAkSZIkqaE5fU6SJElSQzMUSZIkSWporj43hRUrVuQ555wz28OQJEmSdJo8+OCDuzNzZeV2Q9EUzjnnHDZtmuoWGZIkSZLmm4h4str2uk6fi4hLI+KxiNgSEddXaY+IuLFofzgiLjpR34hYFhF3RcTjxfPSYntbRHwqIn4UET8sVowb7/PqYvuW4vOq3YhUkiRJUgOqWyiKiGZKN8y7DDgfeHdEnF+x22XA+uJxLXBzDX2vB+7OzPXA3cV7gH8FkJmvAN4C/HlEjJ/fzcXxxz/r0tN6spIkSZLmrXpeKboY2JKZWzPzGKV74myo2GcDcHuW3Af0RsSaE/TdQOnePxTPVxSvz6cUksjMncAg0F8cb3Fm3lvctPT2sj6SJEmSGlw9a4rWAU+XvR8ALqlhn3Un6Ls6M7cDZOb2iFhVbP8hsCEivgicCby6eD5e9K/8jJM2MjLCwMAAw8PDp9J9Xuno6KCvr4/W1tbZHookSZJUV/UMRdXqdirvFDvVPrX0rXQb8DJgE/Ak8D1g9GSOFRHXUppmx1lnnTWpfWBggJ6eHs455xwWcllSZrJnzx4GBgY499xzZ3s4kiRJUl3Vc/rcAKUrNeP6gGdq3Ge6vjuKKXEUzzsBMnM0Mz+cmRdm5gagF3i8OFbfCcZBcYxbM7M/M/tXrpy0Uh/Dw8MsX758QQcigIhg+fLlDXFFTJIkSapnKHoAWB8R50ZEG/AuYGPFPhuBq4pV6F4D7C+mxk3XdyNwdfH6auAOgIjoiohFxeu3AKOZ+UhxvIMR8Zpi1bmrxvucioUeiMY1ynlKkiRJdZs+l5mjEfEh4E6gGbgtMzdHxHVF+y3A14DLgS3AEeD90/UtDn0D8KWIuAZ4CnhHsX0VcGdEHAe2Ae8tG84HgU8DncDXi8e8s2fPHt785jcD8Oyzz9Lc3Mz4Fa3777+ftra2Kftu2rSJ22+/nRtvvHFGxipJkiTNF1FakE2V+vv7s/LmrY8++igve9nLZmlEE/3RH/0R3d3d/N7v/d5z20ZHR2lpOX05dy6dryRJkvRCRcSDmdlfub2uN2/VCzN0bIy9h49xaHiEo6NjHK8SYN/3vvfxkY98hDe+8Y187GMf4/777+e1r30tr3rVq3jta1/LY489BsA999zD2972NqAUqD7wgQ/whje8gRe96EVePZIkSVJDq+fqc3qBDgyPsOPAxMUOWpubaG1uYv+REY63jHB0ZIxHHn2M/+/rd9LR1srhQwf5zne+Q0tLC9/85jf5/d//fb7yla9MOvZPfvITvvWtb3Hw4EFe+tKX8sEPftDltyVJktSQDEWn6N//3WYeeebAaT3m+WsX84e//vLn3q/saae3q5WR0eMcG0tGxo5zbPQ4I2PHGTl+nMNHxzhybIzXvfVt/Gz3EQB2bt/Gn/3h9Tz185/RFE2Mjo6wf+gYwyNjZCbj0yV/7dd+jfb2dtrb21m1ahU7duygr6+v6rgkSZKkhcxQNIc1RdDe0kx7S/OkthXd7Sxa1M6uzlbOOWMZZy3r4tjYcf7ko3/Ka1/3K9z0qc/z85//nA+84208uecI2waHOHh0lM3PHGD3oaMs7mljYN8R2pqbIJo4cHiYY6PHaW0OV56TJElSQzEUnaLyKzqzJSJoago6Wpvp7SqtPDcydJgLXvoizlvdw+f+y1dobW5i/apunlrcQUdLM8sWtdHSFBw/nhwYGmX0eOnK05N7jzC66ABB0NoStDY3se/wMT5+10/p6+1k3dJO1vV2sqa3o2pIkyRJkuYrQ9EC89GPfpSrr76aj3/847zpTW8CoLOthe72Ftpamljb20lvVxvd3e2cv3YxY8eT9pZmzlzWyZreztIUvbFkZPQ4R0eP84n/8TiV6zus6ml/LiStW9pZFpq6WLe0k+52v1aSJEmaP1ySewpzfUnumfDoo4/ykvNeyrP7hxnYN8S2wSG27Rti2+CR514/MzjMsbHjE/ot6Wx9LjCt6+2kryxArevtZNmiNqfoSZIkacZNtSS3f9LXtFqbmzhzWRdnLuuq2n78eLL70FEGngtMzz8/tecI9/5sD4eOjk7o09HaVISkrqqhafXiDpqbDE2SJEmaGYYivSBNTcGqxR2sWtzBRWctndSeWapdGhg8Mik0bRscYvO2/ew5fGxCn5am4IwlHVNOz1uzpIOOVuuaJEmSdHoYilRXEcGSrlaWdC3h5WuXVN1n6NjYcyHpuel5RXC672d7ePbAMMcrZnmu7GmvEpqef+7p8J5LkiRJqo2hSLOus62Zl6zq5iWruqu2j4wd59n9wxOvMhXPjzxzgLse2cGx0Yl1TYs7WiZNz1tbFppWdFvXJEmSpBJDkea8muqaDh+dPD1v3xAD+47w/a17OFhR19Te0jThytK6iqtNZyzuoKW5aSZOT5IkSbPMUKR5r6kpWNXTwaqeDl5Vpa4JYP/QSFlYOjJhut6j2w+w+9DEuqbmpuCMxR2TwlL5s3VNkiRJC4OhaB7Zs2cPb37zmwF49tlnaW5uZuXKlQDcf//9tLW1Tdv/nnvuoa2tjde+9rV1H+tcs6SzlSWdrZy/dnHV9uGRsarT87btG+L+n+/l2QPDjFUUNq3obqtytanruW1LOq1rkiRJmg8MRfPI8uXLeeihhwD4oz/6I7q7u/m93/u9mvvfc889dHd3N2QoOpGO1mZevLKbF6+sXtc0OnacZw8MV11B7yfbD3L3ozs5WlHX1NPeMuVVpnVLO1nZ3W5dkyRJ0hxgKJrnHnzwQT7ykY9w6NAhVqxYwac//WnWrFnDjTfeyC233EJLSwvnn38+N9xwA7fccgvNzc189rOf5ROf+ASvf/3rZ3v480ZLcxN9S7voW1q9rikz2X3oWNUV9Ab2DXH/E3s5ODyxrqltvK6pSk3Tut7S0uPWNUmSJNWfoWgey0x+67d+izvuuIOVK1fyN3/zN/zBH/wBt912GzfccAM///nPaW9vZ3BwkN7eXq677rqTvrqk2kQEK3vaWdnTzoVn9lbd58BwUddUdpVp274hBgaHuPsnO9l96OiE/ZuCUl3ThLDUNWG6XmebdU2SJEkvlKHoVH39enj2R6f3mGe8Ai67oebdjx49yo9//GPe8pa3ADA2NsaaNWsAuOCCC7jyyiu54ooruOKKK07vOHVKFne0snhNKy9bM3Vd0zODVVbQGxzigSf28XcPb59U17R8UduUK+j19XaxuLPFKXqSJEknYCiaxzKTl7/85dx7772T2r761a/yne98h40bN/LHf/zHbN68eRZGqJPR0drMi1Z286Jp6pp2HDxadXreYzsO8q3HdjI8MrGuqbu9Zcqapr7eTlZ0t9PUZGiSJEmNzVB0qk7iik69tLe3s2vXLu69915++Zd/mZGREX7605/yspe9jKeffpo3vvGNvO51r+Pzn/88hw4doqenhwMHDsz2sHWKWpqfr0GCZZPaM5M9h49NWgxioHje9MReDlSpa1q7pGyKXtn0vL6lnZyxpINW65okSdICZyiax5qamvjyl7/Mb//2b7N//35GR0f53d/9Xc477zze8573sH//fjKTD3/4w/T29vLrv/7rvP3tb+eOO+5woYUFKCJY0d3Oiu52XjlFXdPB4ZGq0/O27RviW4/tYtfByXVNq6e4X1NfUeNkXZMkSZrvIjNPvFcD6u/vz02bNk3Y9uijj/Kyl71slkY08xrtfFWqa9q+f3jCFL2BshD17P5hRivqmpYtaptyBb2+4n5N1jVJkqS5ICIezMz+yu1eKZL0nI7WZs5dsYhzVyyq2j52PNlxYLjq9LzHdx7knp9Ormta1NY85Qp6fcX9mqxrkiRJs8lQJKlmzU3B2t5O1vZ28kvnTG7PTPYePlY1ND0zOMQ/PT3I4JGRCX3amptY09sx5Qp6ZyzpoK3FuiZJklQ/hiJJp01EsLy7neXd7VzQ11t1n0NHR0tLj1dMzdu27wjfeXwXOw8epXxWbwSs7qm8X9PzK+itW9pJV5s/yiRJ0qnzN4mTlJkNUR9hrZnqpbu9hfNW93De6p6q7UdHx3i2qGsaqFgU4qGnB/n6j7czMjbx+7m0q3XKFfTW9XbS22VdkyRJmpqh6CR0dHSwZ88eli9fvqB/wcpM9uzZQ0dHx2wPRQ2ovaWZs5cv4uzlU9c17Tp4lG2DR56bmjcenLbuOsx3H9/NkWNjE/p0tTVPu4Leqh7rmiRJamSGopPQ19fHwMAAu3btmu2h1F1HRwd9fX2zPQxpkuam4IwlHZyxpINXnz25PTMZPDIyoZ7pudX0Bof44dOD7Kuoa2ptDtYsmXp63polndY1SZK0gBmKTkJrayvnnnvubA9D0jQigqWL2li6qI1fXLek6j6Hi7qmyul52waH+IfHd7Pj4PCkuqZVPe1FWOqaFJrW9XayqN0fp5IkzVd1/Vc8Ii4F/hJoBj6ZmTdUtEfRfjlwBHhfZv5gur4RsQz4G+Ac4AngNzJzX0S0Ap8ELirO6/bM/NOizz3AGmCo+Oi3ZubO+py1pLluUXsL61f3sH6KuqZjo8d5dv8wA8W9mspD08MDg3yjSl1Tb1frpBX0+sqWIF9qXZMkSXNW3UJRRDQDNwFvAQaAByJiY2Y+UrbbZcD64nEJcDNwyQn6Xg/cnZk3RMT1xfuPAe8A2jPzFRHRBTwSEV/IzCeKz7oyMyfejVWSqmhraeKs5V2ctbyravvx48muQ0cnT8/bN8QTew7zj1t2c7iirqmztfJ+Tc8vBLFuaSerejpotq5JkqRZUc8rRRcDWzJzK0BEfBHYAJSHog2UrugkcF9E9EbEGkpXgabquwF4Q9H/M8A9lEJRAosiogXoBI4BB+p4fpIaVFNTsHpxB6sXd/Dqs5dOas9M9g+NTFoIYvz5R9v2s/fwsQl9Wpqi7H5NXZOm563p7aC9pXmmTlGSpIZSz1C0Dni67P0ApatBJ9pn3Qn6rs7M7QCZuT0iVhXbv0wpMG0HuoAPZ+besmN8KiLGgK8Af5KuOS2pTiKC3q42erumrms6cqyoa6oSnL73s93sODDM8YqfUqt62lm3tHTz3L4qq+n1dLTOwNlJkrTw1DMUVZsHUhlEptqnlr6VLgbGgLXAUuC7EfHN4mrTlZm5LSJ6KIWi9wK3TxpwxLXAtQBnnXXWCT5Okk5dV1sLL1nVw0tWVa9rGhkr6pqqrKC3edt+7tq8g2Njxyf0WdzR8txCEH1Vbna7fFGbdU2SJFVRz1A0AJxZ9r4PeKbGfdqm6bsjItYUV4nWAOMLJvwm8I3MHAF2RsQ/Av3A1szcBpCZByPi85QC1KRQlJm3ArcC9Pf3eyVJ0qxpbW7izGVdnLls6rqm3YeOVl1B7+m9R7hv6x4OHR2d0KejtYm1vZPrmcan652x2LomSVJjqmcoegBYHxHnAtuAd1EKLuU2Ah8qaoYuAfYXYWfXNH03AlcDNxTPdxTbnwLeFBGfpTR97jXAXxQ1Rr2ZubtYoe5twDfrcsaSNEOamoJViztYtbiDi86qXtd0YGi06gp62waHeOSZA+ypqGtqbgrOWNwxqZ5p/HltbycdrdY1SZIWnrqFoswcjYgPAXdSWlb7tszcHBHXFe23AF+jtBz3FkpLcr9/ur7FoW8AvhQR11AKQu8ott8EfAr4MaXpd5/KzIcjYhFwZxGImikFor+u13lL0lwQESzpamVJ1xJevrZ6XdPQsbHnQlL5CnrbBoe4b+senq1S17Siu31yaBp/vbSTxdY1SZLmoXC9ger6+/tz0yZX8JbUuMbrmqqtoDf+ODY6sa6pp6Nlyul563o7WdFtXZMkafZExIOZ2V+53VuwS5Kqqqmu6fDRyYFpX2lVve9v3cvBirqm9pamiQtAVEzTO2NxBy3NTTNxepIkPcdQJEk6JU1NwaqeDlb1dPCqKnVNAPuHRsrC0pEJ0/Ue3X6A3YemqGuqUtM0/mxdkyTpdDMUSZLqZklnK0s6Wzl/7eKq7cMjY9Wn5+0b4v6f7+XZA8OMVRQ2rehuq3K1qeu5bUs6rWuSJJ0cQ5EkadZ0tDbz4pXdvHhld9X20bHjPHtguGpN00+2H+TuR3dytLKuqb1lyqtM65Z2srK73bomSdIEhiJJ0pzV0txE39Iu+pZWr2vKTHYfOlZ1Bb2BfUPc/8ReDg5PrGtqG69rqlLTtK63kzVLrGuSpEZjKJIkzVsRwcqedlb2tHPhmb1V9zkwXNQ1la+ct2+IgcEh7v7JTnYfOjph/6bgufs1VVtBb11vJ51t1jVJ0kJiKJIkLWiLO1pZvKaVl62Zuq7pmcEqK+gNDvHAE/v4u4e3T6prWr6obcoV9Pp6u1jc2eIUPUmaRwxFkqSG1tHazItWdvOiaeqadhwsLT0+Hp4GivD00x0H+dZjOxkemVjX1N3eMmVNU19vJyu622lqMjRJ0lxhKJIkaRotzc/XIFWTmew9fGzClaaBsitODz65j/1DIxP6tDU3sba3bIpe2fS8vqWdnLGkg1brmiRpxhiKJEl6ASKC5d3tLO9u54K+3qr7HBwe4ZnB4ecWghgoC1D3PLaLnQcn1zWtnuJ+TX1LO1nb20lXm/+ES9Lp4k9USZLqrKejlZee0cpLz+ip2n50dIztg8MT6pnGV9P7wVP7+OrD2xmtqGtatqhtyhX0+or7NVnXJEm1MRRJkjTL2luaOWfFIs5Zsahq+9jxZOfB4arT87bsOsS3f7qLoZGxCX0WtTVPuYJeX3G/JuuaJKnEUCRJ0hzX3BSsWdLJmiWd9Fdpz0z2HRl57urSQMXNbv/p6UEGj0yua1rT2zHlCnpnLOmgrcW6JkmNwVAkSdI8FxEsW9TGskVtvKJvSdV9Dh0dLa2eV1HTtG3fEb7zeKmuKbP8mLC6p/J+Tc+voLduqXVNkhYOf5pJktQAuttbOG91D+etnrqu6dn9w1VC0xAPPT3I13+8nZGxiXVNS7tap1xBb21vJ0u7rGuSND8YiiRJEu0tzZy9fBFnL5+6rmnXwaNVp+dt3XWY7z6+myPHJtY1dbU1s7Z38iIQ4+9X9XTQbF2TpDnAUCRJkk6ouSk4Y0kHZyzp4NVnT27PTAaPjExaCGLb4BG2DQ7x8MAg+yrqmlqbS8csv9LUVxag1vR20N7SPENnKKmRGYokSdILFhEsXdTG0kVt/OK66nVNh4u6psrpedsGh/jHLbvZcXB4Ul3Tyu72qvVM4yGqu91fZSS9cP4kkSRJM2JRewvrV/ewfoq6pmOjx3l2/zADxU1uy0PTj7bt587Nz06qa1rS2Trl9Lx1vZ0sW9RmXZOkEzIUSZKkOaGtpYmzlndx1vKuqu3Hjye7Dh2dPD1v3xBP7jnM97bs5nBFXVNnazNreztYt7Sramhavdi6JkmGIkmSNE80NQWrF3ewenEHrz576aT2zGT/0MikhSDGn3+8bT97Dx+b0Kelqayuqcr0vLXWNUkNwVAkSZIWhIigt6uN3q6p65qOHCvqmqoEp3t/tocdB4Y5PnGGHit72quEpuefezpaZ+DsJNWToUiSJDWMrrYWXrKqh5esql7XNDJW1DVVWUFv87b93LV5B8fGjk/os7ijZcrpeeuWdrLcuiZpzjMUSZIkFVqbmzhzWRdnLpu6rmn3oaNVV9B7eu8R7tu6h0NHRyf06Whteu5+TRNDU2mK3uqedlqam2bi9CRNwVAkSZJUo6amYNXiDlYt7uCis6rXNR0YGq26gt62wSEeeeYAeyrqmpqbgjMWd0w5PW9tbycdrdY1SfVkKJIkSTpNIoIlXa0s6VrCy9dWr2saOjb2XEgqX0Fv2+AQ923dw7NV6ppWFPdrmhCaxl8v7WSxdU3SC2IokiRJmkGdbc28ZFU3L1nVXbV9vK6p2gp6j2w/wF2P7uDY6MS6pp6Olimn563r7WRFt3VN0nQMRZIkSXNITXVNh49Onp63r7Sq3ve37uVgRV1Te0vTxAUgKqbpnbG4w7omNTRDkSRJ0jzS1BSs6ulgVU8Hr6pS1wSwf2ikLCwdmTBd79HtB9h9aIq6pio1TePP1jVpIatrKIqIS4G/BJqBT2bmDRXtUbRfDhwB3peZP5iub0QsA/4GOAd4AviNzNwXEa3AJ4GLivO6PTP/tOjzauDTQCfwNeB3MrNitq4kSdLCsKSzlSWdrZy/dnHV9uGRMZ4ZrHKlaXCI+3++l2cPDDNWUdi0orutytWmrue2Lem0rknzV91CUUQ0AzcBbwEGgAciYmNmPlK222XA+uJxCXAzcMkJ+l4P3J2ZN0TE9cX7jwHvANoz8xUR0QU8EhFfyMwniuNeC9xHKRRdCny9XucuSZI0l3W0NvOild28aGX1uqbRsePsOHh00kIQA/uG+MmzB7n70Z0craxram+Z8irTuqWdrOxut65Jc1Y9rxRdDGzJzK0AEfFFYANQHoo2ULqik8B9EdEbEWsoXQWaqu8G4A1F/88A91AKRQksiogWSleEjgEHiuMtzsx7i2PdDlyBoUiSJKmqluam564GwbJJ7ZnJnsPHJtU1jd/09oEn9nJgeGJdU1vL88esFpzOWNJBq3VNmiX1DEXrgKfL3g9Quhp0on3WnaDv6szcDpCZ2yNiVbH9y5QC03agC/hwZu6NiP6if+VnSJIk6RREBCu621nR3c4rz+ytus/B4ZGq0/O27Rvifzy2k10Hj07Yvyl47n5N1VbQW9fbSWebdU2qj3qGomrXRyvreKbap5a+lS4GxoC1wFLguxHxzZM5VkRcS2maHWedddYJPk6SJElT6elo5RfOaOUXzpi6rmn7/uEJU/TGQ9OmJ/fxdw9vn1TXtHxR25Qr6PX1drG4s8Upejol9QxFA8CZZe/7gGdq3Kdtmr47ImJNcZVoDbCz2P6bwDcycwTYGRH/CPQD3y36TzcOADLzVuBWgP7+fhdikCRJqpOO1mbOXbGIc1csqto+djzZcWC46vS8n+44yLce28nwyMS6pu72lilrmvp6O1nR3U5Tk6FJk9UzFD0ArI+Ic4FtwLsoBZdyG4EPFTVDlwD7i7Cza5q+G4GrgRuK5zuK7U8Bb4qIz1KaPvca4C+K4x2MiNcA3weuAj5RlzOWJEnSadHcFKzt7WRtbye/dM7k9sxk7+FjVUPTtn1DPPjkPvYPjUzo09bcxNresil6ZdPz+pZa19TI6haKMnM0Ij4E3ElpWe3bMnNzRFxXtN9CaSW4y4EtlJbkfv90fYtD3wB8KSKuoRSE3lFsvwn4FPBjSlPmPpWZDxdtH+T5Jbm/jossSJIkzWsRwfLudpZ3t3NBX2/VfQ4dHa06PW/b4BD3PLaLnVXqmlaX3a9pbe/EK03rlnbS1eZtPhei8HY91fX39+emTZtmexiSJEmqk6OjY2wfHJ60EMS2wdINb7cPDjNaUde0tKt1yitN63o76e1qta5pDouIBzOzv3K7UVeSJEkNqb2lmXNWLOKcaeqadh4crjo972e7DvOdn+5maGRsQp9Fbc2lK0wVdU19xWp6q3qsa5qLDEWSJElSFc1NwZolnaxZ0smkSwuU6pr2HRl57urSQMV9mx56epDBIxPrmlqbS8esthDEuqWlz2prsa5pphmKJEmSpFMQESxb1MayRW28om9J1X0OHx2tMj1viG37jvDdx0t1TeXVLBGwqqe9CEtdk0LTut5OFrX7K/zp5n9RSZIkqU4Wtbdw3uoezlvdU7X92Ohxtu+vFpqG+OHTg3zjx9sZGZtY19Tb1TrpXk19ZTe7XWpd00kzFEmSJEmzpK2libOXL+Ls5VPXNe06eLTq9Lyf7z7MP2zZzZFjE+uausbrmiaFptL7VT0dNFvXNIGhSJIkSZqjmpuCM5Z0cMaSDl599uT2zGTwyMikhSDGV9B7eGCQfVXqms5Y0jFhBb3y6Xlrejtob2meoTOcGwxFkiRJ0jwVESxd1MbSRW384rqp65qeGZw8PW/b4BD/uGU3Ow4OT6prWtndXnUhiPEQ1b3A6poW1tlIkiRJmmBRewvrV/ewfpq6pmf3DzNQ3OS2PDT9aNt+/n7zDo6NHZ/QZ0ln65TT89b1drJsUdu8qmsyFEmSJEkNrK2libOWd3HW8q6q7cePJ7sOHZ08PW/fEE/uOcz3tuzmcEVdU2drM2t7O1i3tItXndnLh99y3kycyikzFEmSJEmaUlNTsHpxB6sXd/Dqs5dOas9M9g+NTFoIYvx5y65DszDqk2MokiRJknTKIoLerjZ6u6aua5rrvF2uJEmSpIZmKJIkSZLU0AxFkiRJkhqaoUiSJElSQzMUSZIkSWpohiJJkiRJDc1QJEmSJKmhGYokSZIkNTRDkSRJkqSGZiiSJEmS1NAMRZIkSZIamqFIkiRJUkMzFEmSJElqaIYiSZIkSQ3NUCRJkiSpoRmKJEmSJDU0Q5EkSZKkhmYokiRJktTQ6hqKIuLSiHgsIrZExPVV2iMibizaH46Ii07UNyKWRcRdEfF48by02H5lRDxU9jgeERcWbfcUxxpvW1XP85YkSZI0f9QtFEVEM3ATcBlwPvDuiDi/YrfLgPXF41rg5hr6Xg/cnZnrgbuL92Tm5zLzwsy8EHgv8ERmPlT2WVeOt2fmztN9vpIkSZLmp3peKboY2JKZWzPzGPBFYEPFPhuA27PkPqA3ItacoO8G4DPF688AV1T57HcDXzitZyNJkiRpQapnKFoHPF32fqDYVss+0/VdnZnbAYrnalPh3snkUPSpYurcv4uIqDbgiLg2IjZFxKZdu3ZNfWaSJEmSFox6hqJqwSNr3KeWvtU/NOIS4Ehm/rhs85WZ+Qrg9cXjvdX6Zuatmdmfmf0rV66s5eMkSZIkzXP1DEUDwJll7/uAZ2rcZ7q+O4opdhTPlfVB76LiKlFmbiueDwKfpzQ9T5IkSZLqGooeANZHxLkR0UYprGys2GcjcFWxCt1rgP3FlLjp+m4Eri5eXw3cMX6wiGgC3kGpBml8W0tErChetwJvA8qvIkmSJElqYC31OnBmjkbEh4A7gWbgtszcHBHXFe23AF8DLge2AEeA90/Xtzj0DcCXIuIa4ClKIWjcrwADmbm1bFs7cGcRiJqBbwJ/XY9zliRJkjT/RGZNpToNp7+/Pzdt2jTbw5AkSZJ0mkTEg5nZX7m9rjdvlSRJkqS5zlAkSZIkqaEZiiRJkiQ1NEORJEmSpIZWUyiKiN+JiMXF0tn/NSJ+EBFvrffgJEmSJKnear1S9IHMPAC8FVhJaensG+o2KkmSJEmaIbWGoiieLwc+lZk/LNsmSZIkSfNWraHowYj4e0qh6M6I6AGO129YkiRJkjQzWmrc7xrgQmBrZh6JiGWUptBJkiRJ0rxW65WiXwYey8zBiHgP8G+B/fUbliRJkiTNjFpD0c3AkYh4JfBR4Eng9rqNSpIkSZJmSK2haDQzE9gA/GVm/iXQU79hSZIkSdLMqLWm6GBE/BvgvcDrI6IZaK3fsCRJkiRpZtR6peidwFFK9yt6FlgH/Ke6jUqSJEmSZkhNoagIQp8DlkTE24DhzLSmSJIkSdK8V1MoiojfAO4H3gH8BvD9iHh7PQcmSZIkSTOh1pqiPwB+KTN3AkTESuCbwJfrNTBJkiRJmgm11hQ1jQeiwp6T6CtJkiRJc1atV4q+ERF3Al8o3r8T+Fp9hiRJkiRJM6emUJSZ/zoi/iXwPwEB3JqZf1vXkUmSJEnSDKj1ShGZ+RXgK3UciyRJkiTNuGlDUUQcBLJaE5CZubguo5IkSZKkGTJtKMrMnpkaiCRJkiTNBleQkyRJktTQDEWSJEmSGpqhSJIkSVJDMxRJkiRJamiGIkmSJEkNzVAkSZIkqaHVNRRFxKUR8VhEbImI66u0R0TcWLQ/HBEXnahvRCyLiLsi4vHieWmx/cqIeKjscTwiLizaXh0RPyqOdWNERD3PW5IkSdL8UbdQFBHNwE3AZcD5wLsj4vyK3S4D1hePa4Gba+h7PXB3Zq4H7i7ek5mfy8wLM/NC4L3AE5n5UNHn5uL445916ek+X0mSJEnzUz2vFF0MbMnMrZl5DPgisKFinw3A7VlyH9AbEWtO0HcD8Jni9WeAK6p89ruBLwAUx1ucmfdmZgK3T9FHkiRJUgOqZyhaBzxd9n6g2FbLPtP1XZ2Z2wGK51VVPvudFKGo6DdwgnEAEBHXRsSmiNi0a9euKU5LkiRJ0kJSz1BUrW4na9ynlr7VPzTiEuBIZv74JMZR2ph5a2b2Z2b/ypUra/k4SZIkSfNcPUPRAHBm2fs+4Jka95mu745iStz41LidFcd8F89fJRr/jL4TjEOSJElSg6pnKHoAWB8R50ZEG6WwsrFin43AVcUqdK8B9hdT4qbruxG4unh9NXDH+MEiogl4B6UaJOC5KXYHI+I1xapzV5X3kSRJktTYWup14MwcjYgPAXcCzcBtmbk5Iq4r2m8BvgZcDmwBjgDvn65vcegbgC9FxDXAU5RC0LhfAQYyc2vFcD4IfBroBL5ePCRJkiSJKC3Ipkr9/f25adOm2R6GJEmSpNMkIh7MzP7K7XW9easkSZIkzXWGIkmSJEkNzVAkSZIkqaEZiiRJkiQ1NEORJEmSpIZmKJIkSZLU0AxFkiRJkhqaoUiSJElSQzMUSZIkSWpohiJJkiRJDc1QJEmSJKmhGYokSZIkNTRDkSRJkqSGZiiSJEmS1NAMRZIkSZIamqFIkiRJUkMzFEmSJElqaIYiSZIkSQ3NUCRJkiSpoRmKJEmSJDU0Q5EkSZKkhmYokiRJktTQDEWSJEmSGpqhSJIkSVJDMxRJkiRJamiGIkmSJEkNzVAkSZIkqaEZiiRJkiQ1tLqGooi4NCIei4gtEXF9lfaIiBuL9ocj4qIT9Y2IZRFxV0Q8XjwvLWu7ICLujYjNEfGjiOgott9THOuh4rGqnuctSZIkaf6oWyiKiGbgJuAy4Hzg3RFxfsVulwHri8e1wM019L0euDsz1wN3F++JiBbgs8B1mfly4A3ASNlnXZmZFxaPnaf5dCVJkiTNU/W8UnQxsCUzt2bmMeCLwIaKfTYAt2fJfUBvRKw5Qd8NwGeK158BrihevxV4ODN/CJCZezJzrE7nJkmSJGmBqGcoWgc8XfZ+oNhWyz7T9V2dmdsBiufxqXDnARkRd0bEDyLioxWf9ali6ty/i4g41ZOSJEmStLDUMxRVCx5Z4z619K3UArwOuLJ4/hcR8eai7crMfAXw+uLx3qoDjrg2IjZFxKZdu3ad4OMkSZIkLQT1DEUDwJll7/uAZ2rcZ7q+O4opdhTP4/VBA8C3M3N3Zh4BvgZcBJCZ24rng8DnKU3PmyQzb83M/szsX7ly5UmcqiRJkqT5qp6h6AFgfUScGxFtwLuAjRX7bASuKlahew2wv5gSN13fjcDVxeurgTuK13cCF0REV7Howq8Cj0RES0SsAIiIVuBtwI/rccKSJEmS5p+Weh04M0cj4kOUwkozcFtmbo6I64r2Wyhdzbkc2AIcAd4/Xd/i0DcAX4qIa4CngHcUffZFxMcpBaoEvpaZX42IRcCdRSBqBr4J/HW9zluSJEnS/BKZJyrVaUz9/f25adOm2R6GJEmSpNMkIh7MzP7K7XW9easkSZIkzXWGIkmSJEkNzVAkSZIkqaEZiiRJkiQ1NEORJEmSpIZmKJIkSZLU0AxFkiRJkhqaoUiSJElSQzMUSZIkSWpohiJJkiRJDc1QJEmSJKmhGYokSZIkNTRDkSRJkqSGZiiSJEmS1NAMRZIkSZIamqFIkiRJUkMzFEmSJElqaIYiSZIkSQ3NUCRJkiSpoRmKJEmSJDU0Q5EkSZKkhmYokiRJktTQDEWSJEmSGpqhSJIkSVJDMxRJkiRJamiGIkmSJEkNzVAkSZIkqaEZiiRJkiQ1NEORJEmSpIZW11AUEZdGxGMRsSUirq/SHhFxY9H+cERcdKK+EbEsIu6KiMeL56VlbRdExL0RsTkifhQRHcX2VxfvtxSfF/U8b0mSJEnzR91CUUQ0AzcBlwHnA++OiPMrdrsMWF88rgVurqHv9cDdmbkeuLt4T0S0AJ8FrsvMlwNvAEaKPjcXxx//rEtP8+lKkiRJmqfqeaXoYmBLZm7NzGPAF4ENFftsAG7PkvuA3ohYc4K+G4DPFK8/A1xRvH4r8HBm/hAgM/dk5lhxvMWZeW9mJnB7WR9JkiRJDa6eoWgd8HTZ+4FiWy37TNd3dWZuByieVxXbzwMyIu6MiB9ExEfLPmPgBOOQJEmS1KBa6njsanU7WeM+tfSt1AK8Dvgl4Ahwd0Q8CByo9VgRcS2laXacddZZJ/i4GXDfzXDPDdDaBa0dpeeWDmjtLD1aOqq0jb/vhJbO5/ed7n1LBzS55oYkSZIaUz1D0QBwZtn7PuCZGvdpm6bvjohYk5nbi6lxO8uO9e3M3A0QEV8DLqJUZ9R3gnEAkJm3ArcC9Pf3nyiE1d/KX4ALfgNGjsDIMIwMwehQ6fnQzonvR4ZL++XYqX1WS8cUIauGUNXaYQCTJEnSvFXPUPQAsD4izgW2Ae8CfrNin43AhyLii8AlwP4i7Oyapu9G4GrghuL5jmL7ncBHI6ILOAb8KvCfi+MdjIjXAN8HrgI+UZczPt1e/MbS42SMjTwfop4LTEPVA9TocFngqnw/hwNY5VUxA5gkSZJegLqFoswcjYgPUQorzcBtmbk5Iq4r2m8BvgZcDmyhNOXt/dP1LQ59A/CliLgGeAp4R9FnX0R8nFIYS+BrmfnVos8HgU8DncDXi8fC1NwKzUugY0n9P6s8gFWGqoUawKYKZAYwSZKkeStKC7KpUn9/f27atGm2h6Fx0wWwCSFqqPYANtUVtLkawMbfG8AkSZJOSUQ8mJn9ldvrOX1OOn3myhWwaUNV+fsZuAJWGbIMYJIkSafEUCRVmncBrGKa4qEd1acwns4AVrn6oQFMkiTNY4YiaTbN+wD2bPX+9QxgUy4/bwCTJEmnxlAkNYqZCmCZpQA2OjQDAewI5PFTG+cLCmCVV8UMYJIkzWeGIkmnVwS0tJUeMxrATlDXtWAC2BTvDWCSJJ0yQ5Gk+WvOBLDKq2ILPICNHy/i9P43liRplhiKJKkWczaAncS9wk57AKucOmgAkyTNT4YiSZpr5lsAq3ZV7Gi9A1gtC20YwCRJtTEUSVIjWwgBbHh/9f51C2BTLD9vAJOkectQJEmaGQawyU41gE25/LwBTJJOhaFIkrTwzEYAq6Wua0EFsKkCmQFM0vxjKJIk6YUoD2D1NlUAm3K1QwOYJNXCUCRJ0nwxpwPYFNMUZySAVVv50AAmqXaGIkmSNNl8DGCV/esZwGpeaMMAJs0HhiJJkjS7FkIAGxqsuHlzHQNYLaHKACadFEORJElqHAsxgI3vPxsBrHKaogFM85ShSJIkqR5mPIAdq62ua9YCWEwTqE4hgFUNZAYwnRpDkSRJ0nwXAS3tpUdnb30/a7oANuXS9AssgJVfFWtpN4AtAIYiSZIk1W6uBrAp389AAJt0pcoANt8YiiRJkjQ3zbsAVuWqWLUANnIEyFMYZEwMSdWWnzeAnRJDkSRJkrQgAti+iasfju9frwA2XV1XeVv3ajj7l0/3f8XTylAkSZIkzaRGC2BnXgLX/H19z/MFMhRJkiRJC9WsBLCKUNXUWt/PPQ0MRZIkSZJeuAkBbLYHc3KaZnsAkiRJkjSbDEWSJEmSGpqhSJIkSVJDMxRJkiRJamiGIkmSJEkNra6hKCIujYjHImJLRFxfpT0i4sai/eGIuOhEfSNiWUTcFRGPF89Li+3nRMRQRDxUPG4p63NPcazxtlX1PG9JkiRJ80fdQlFENAM3AZcB5wPvjojzK3a7DFhfPK4Fbq6h7/XA3Zm5Hri7eD/uZ5l5YfG4ruKzrixr23naTlSSJEnSvFbPK0UXA1syc2tmHgO+CGyo2GcDcHuW3Af0RsSaE/TdAHymeP0Z4Io6noMkSZKkBa6eoWgd8HTZ+4FiWy37TNd3dWZuByiey6fCnRsR/xQR346I11d81qeKqXP/LiLilM5IkiRJ0oJTz1BULXhkjfvU0rfSduCszHwV8BHg8xGxuGi7MjNfAby+eLy36oAjro2ITRGxadeuXSf4OEmSJEkLQUsdjz0AnFn2vg94psZ92qbpuyMi1mTm9mKq3U6AzDwKHC1ePxgRPwPOAzZl5rZi+8GI+Dyl6Xm3Vw44M28FbgWIiF0R8eRJn/XptwLYPduD0Lzgd0W18HuiWvg9Ua38rqgWc+l7cna1jfUMRQ8A6yPiXGAb8C7gNyv22Qh8KCK+CFwC7C/Czq5p+m4ErgZuKJ7vAIiIlcDezByLiBdRWrxha0S0AL2ZuTsiWoG3Ad880eAzc+ULOPfTJiI2ZWb/bI9Dc5/fFdXC74lq4fdEtfK7olrMh+9J3UJRZo5GxIeAO4Fm4LbM3BwR1xXttwBfAy4HtgBHgPdP17c49A3AlyLiGuAp4B3F9l8B/kNEjAJjwHWZuTciFgF3FoGomVIg+ut6nbckSZKk+SUyT1Sqo9k0H5K15ga/K6qF3xPVwu+JauV3RbWYD9+Tut68VafFrbM9AM0bfldUC78nqoXfE9XK74pqMee/J14pkiRJktTQvFIkSZIkqaEZiuaIiLg0Ih6LiC0RcX2V9oiIG4v2hyPiotkYp2ZXDd+TK4vvx8MR8b2IeOVsjFOz70TflbL9fikixiLi7TM5Ps0NtXxPIuINxc3PN0fEt2d6jJp9NfzbsyQi/i4iflh8T94/G+PU7IqI2yJiZ0T8eIr2Of27rKFoDoiIZuAm4DLgfODdEXF+xW6XUVpmfD1wLXDzjA5Ss67G78nPgV/NzAuAP2YezOHV6Vfjd2V8vz+jtNKnGkwt35OI6AX+C/DPM/PlPL/iqxpEjT9P/nfgkcx8JfAG4M8jom1GB6q54NPApdO0z+nfZQ1Fc8PFwJbM3JqZx4AvAhsq9tkA3J4l9wG9xc1r1ThO+D3JzO9l5r7i7X2UbnysxlPLzxSA3wK+QnETbDWcWr4nvwn898x8CiAz/a40nlq+Jwn0REQA3cBeYHRmh6nZlpnfofT/fipz+ndZQ9HcsA54uuz9QLHtZPfRwnay34FrgK/XdUSaq074XYmIdcC/AG6ZwXFpbqnlZ8p5wNKIuCciHoyIq2ZsdJoravme/BXwMuAZ4EfA72Tm8ZkZnuaROf27bN1u3qqTElW2VS4LWMs+Wthq/g5ExBsphaLX1XVEmqtq+a78BfCxzBwr/XFXDaiW70kL8GrgzUAncG9E3JeZP6334DRn1PI9+WfAQ8CbgBcDd0XEdzPzQJ3HpvllTv8uayiaGwaAM8ve91H6a8vJ7qOFrabvQERcAHwSuCwz98zQ2DS31PJd6Qe+WASiFcDlETGamf/vjIxQc0Gt//bszszDwOGI+A7wSsBQ1Dhq+Z68H7ghS/d52RIRPwd+Abh/ZoaoeWJO/y7r9Lm54QFgfUScWxQmvgvYWLHPRuCqYuWO1wD7M3P7TA9Us+qE35OIOAv478B7/UtuQzvhdyUzz83MczLzHODLwP9mIGo4tfzbcwfw+ohoiYgu4BLg0Rkep2ZXLd+TpyhdTSQiVgMvBbbO6Cg1H8zp32W9UjQHZOZoRHyI0gpQzcBtmbk5Iq4r2m8BvgZcDmwBjlD6q4waSI3fk/8DWA78l+IKwGhm9s/WmDU7avyuqMHV8j3JzEcj4hvAw8Bx4JOZWXW5XS1MNf48+WPg0xHxI0pTpD6WmbtnbdCaFRHxBUqrD66IiAHgD4FWmB+/y0bpSqckSZIkNSanz0mSJElqaIYiSZIkSQ3NUCRJkiSpoRmKJEmSJDU0Q5EkSZKkhmYokiQtCBExFhEPlT2uP43HPiciXIpakhYo71MkSVoohjLzwtkehCRp/vFKkSRpQYuIJyLizyLi/uLxkmL72RFxd0Q8XDyfVWxfHRF/GxE/LB6vLQ7VHBF/HRGbI+LvI6Jz1k5KknRaGYokSQtFZ8X0uXeWtR3IzIuBvwL+otj2V8DtmXkB8DngxmL7jcC3M/OVwEXA5mL7euCmzHw5MAj8y7qejSRpxkRmzvYYJEl6wSLiUGZ2V9n+BPCmzNwaEa3As5m5PCJ2A2syc6TYvj0zV0TELqAvM4+WHeMc4K7MXF+8/xjQmpl/MgOnJkmqM68USZIaQU7xeqp9qjla9noM63IlacEwFEmSGsE7y57vLV5/D3hX8fpK4B+K13cDHwSIiOaIWDxTg5QkzQ7/yiVJWig6I+KhsvffyMzxZbnbI+L7lP4Y+O5i228Dt0XEvwZ2Ae8vtv8OcGtEXEPpitAHge31HrwkafZYUyRJWtCKmqL+zNw922ORJM1NTp+TJEmS1NC8UiRJkiSpoXmlSJIkSVJDMxRJkiRJamiGIkmSJEkNzVAkSZIkqaEZiiRJkiQ1NEORJEmSpIb2/wMHvyiSDH/8iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation iou_score values\n",
    "import matplotlib.pyplot as plt\n",
    "his = pd.read_csv('model3/history.csv')\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['loss'])\n",
    "plt.plot(his['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b> From the above plot we can ensure that model is not overfitted</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXY9uP7cO_sE"
   },
   "source": [
    "### 4. Data augmentation with spectogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EShBfiERO_sE"
   },
   "source": [
    "1. use convert_to_spectrogram and convert the padded data from train and test data to spectogram data.\n",
    "2. The shape of train data will be 14400 x 64 x 35 and shape of test_data will be 400 x 64 x35\n",
    "3. Define the model similar to model 2 and fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "QpVMCEW3O_sE"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 64, 35)\n",
      "(400, 64, 35)\n"
     ]
    }
   ],
   "source": [
    "X_train_spectrogram = np.array(convert_to_spectrogram(X_train_pad_seq))\n",
    "X_test_spectrogram = np.array(convert_to_spectrogram(X_test_pad_seq))\n",
    "\n",
    "\n",
    "print(X_train_spectrogram.shape)\n",
    "print(X_test_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " X_train_pad_seq_input (Inpu  [(None, 64, 35)]         0         \n",
      " tLayer)                                                         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64, 128)           83968     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 128)               128       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,898\n",
      "Trainable params: 101,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# write the architecture of the model\n",
    "#print model.summary and make sure that it is following point 2 mentioned above\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_layer = Input(shape=(64, 35), name=\"X_train_pad_seq_input\", dtype='float32')\n",
    "\n",
    "lstm_output = LSTM(128, return_sequences=True, kernel_initializer=tf.keras.initializers.HeUniform())(input_layer)\n",
    "\n",
    "global_pooling = GlobalAveragePooling1D()(lstm_output)\n",
    "\n",
    "fc1 = Dense(128, kernel_initializer=tf.keras.initializers.HeUniform())(global_pooling)\n",
    "\n",
    "gelu_1 = tf.keras.layers.PReLU()(fc1)\n",
    "\n",
    "droup_1 = Dropout(0.2)(gelu_1)\n",
    "\n",
    "output = Dense(10,activation='softmax')(droup_1)\n",
    "\n",
    "model4 = Model(inputs = [input_layer], outputs = output) \n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model4, to_file='model4/model4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 64, 35)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 64, 35)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "40RMwgJ6O_sE"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.8\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.x_test = validation_data[0]\n",
    "        self.y_test = validation_data[1]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label = np.argmax(val_predict, axis = 1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label, average='micro')\n",
    "        print(\"val_F1_score: \", val_f1)\n",
    "        \n",
    "        \n",
    "        if(val_f1 > 0.80):\n",
    "            print(\"\\nReached %2.2f%% val_F1_score, so stopping training!!\" %(THRESHOLD))\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "        \n",
    "metrics = Metrics(validation_data=([X_test_spectrogram], y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 14:00:31.092361: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-03 14:00:31.092401: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-03 14:00:31.095870: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 14:00:31.095890: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-03 14:00:31.095895: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 14:00:31.095900: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-03 14:00:31.095950: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-03 14:00:31.095995: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-03 14:00:31.095999: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 14:00:31.096002: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    }
   ],
   "source": [
    "tensorboard4 = TensorBoard(log_dir='model4/model4_logs'.format(time()), histogram_freq=1, write_graph=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks4 = [\n",
    "    ModelCheckpoint(filepath='./model4/best_model_4.h5', save_weights_only = True, save_best_only = True, \\\n",
    "                                       mode = 'max', monitor = 'val_accuracy', verbose = 1),\n",
    "    tf.keras.callbacks.CSVLogger('./model4/history.csv'),\n",
    "]\n",
    "\n",
    "#compile model.\n",
    "model4.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0006),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "  1/225 [..............................] - ETA: 4:39 - loss: 2.5051 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 14:07:22.437954: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-09-03 14:07:22.437983: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-09-03 14:07:22.438105: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.438115: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.438120: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.438124: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-09-03 14:07:22.554106: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-09-03 14:07:22.555258: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.555273: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.555278: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-09-03 14:07:22.573473: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.573492: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-09-03 14:07:22.573498: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-09-03 14:07:22.598806: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-09-03 14:07:22.624798: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/225 [..............................] - ETA: 27s - loss: 2.5233 - accuracy: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 14:07:22.644273: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.trace.json.gz\n",
      "2022-09-03 14:07:22.686045: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22\n",
      "\n",
      "2022-09-03 14:07:22.691480: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.memory_profile.json.gz\n",
      "2022-09-03 14:07:22.692014: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22\n",
      "Dumped tool data for xplane.pb to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model4/model4_logs/train/plugins/profile/2022_09_03_14_07_22/AI-iiitg.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - ETA: 0s - loss: 2.1742 - accuracy: 0.1992\n",
      "Epoch 1: val_accuracy improved from -inf to 0.30500, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.305\n",
      "225/225 [==============================] - 14s 56ms/step - loss: 2.1742 - accuracy: 0.1992 - val_loss: 2.0058 - val_accuracy: 0.3050\n",
      "Epoch 2/3000\n",
      "224/225 [============================>.] - ETA: 0s - loss: 1.9218 - accuracy: 0.3292\n",
      "Epoch 2: val_accuracy improved from 0.30500 to 0.42250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.4225\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 1.9215 - accuracy: 0.3293 - val_loss: 1.8040 - val_accuracy: 0.4225\n",
      "Epoch 3/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.7148 - accuracy: 0.4094\n",
      "Epoch 3: val_accuracy improved from 0.42250 to 0.51750, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5175\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 1.7148 - accuracy: 0.4094 - val_loss: 1.6113 - val_accuracy: 0.5175\n",
      "Epoch 4/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.5507 - accuracy: 0.4550\n",
      "Epoch 4: val_accuracy improved from 0.51750 to 0.54250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.5425\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.5507 - accuracy: 0.4550 - val_loss: 1.4936 - val_accuracy: 0.5425\n",
      "Epoch 5/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4465 - accuracy: 0.4992\n",
      "Epoch 5: val_accuracy improved from 0.54250 to 0.54750, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5475\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.4465 - accuracy: 0.4992 - val_loss: 1.3819 - val_accuracy: 0.5475\n",
      "Epoch 6/3000\n",
      "224/225 [============================>.] - ETA: 0s - loss: 1.3544 - accuracy: 0.5263\n",
      "Epoch 6: val_accuracy improved from 0.54750 to 0.59250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.5925\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.3543 - accuracy: 0.5262 - val_loss: 1.2822 - val_accuracy: 0.5925\n",
      "Epoch 7/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2762 - accuracy: 0.5556\n",
      "Epoch 7: val_accuracy did not improve from 0.59250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.5725\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.2762 - accuracy: 0.5556 - val_loss: 1.2577 - val_accuracy: 0.5725\n",
      "Epoch 8/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2036 - accuracy: 0.5845\n",
      "Epoch 8: val_accuracy did not improve from 0.59250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.575\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.2036 - accuracy: 0.5845 - val_loss: 1.2351 - val_accuracy: 0.5750\n",
      "Epoch 9/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1392 - accuracy: 0.6086\n",
      "Epoch 9: val_accuracy did not improve from 0.59250\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.575\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.1392 - accuracy: 0.6086 - val_loss: 1.1931 - val_accuracy: 0.5750\n",
      "Epoch 10/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0959 - accuracy: 0.6221\n",
      "Epoch 10: val_accuracy improved from 0.59250 to 0.60000, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.6\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.0959 - accuracy: 0.6221 - val_loss: 1.1255 - val_accuracy: 0.6000\n",
      "Epoch 11/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0470 - accuracy: 0.6433\n",
      "Epoch 11: val_accuracy improved from 0.60000 to 0.65250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6525\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.0470 - accuracy: 0.6433 - val_loss: 1.0577 - val_accuracy: 0.6525\n",
      "Epoch 12/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6483\n",
      "Epoch 12: val_accuracy improved from 0.65250 to 0.66000, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.66\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.0083 - accuracy: 0.6483 - val_loss: 1.0041 - val_accuracy: 0.6600\n",
      "Epoch 13/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.6680\n",
      "Epoch 13: val_accuracy improved from 0.66000 to 0.69000, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.69\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.9672 - accuracy: 0.6680 - val_loss: 0.9912 - val_accuracy: 0.6900\n",
      "Epoch 14/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9416 - accuracy: 0.6774\n",
      "Epoch 14: val_accuracy improved from 0.69000 to 0.69250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6925\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.9416 - accuracy: 0.6774 - val_loss: 0.9662 - val_accuracy: 0.6925\n",
      "Epoch 15/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.6929\n",
      "Epoch 15: val_accuracy improved from 0.69250 to 0.70000, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.9032 - accuracy: 0.6929 - val_loss: 0.9250 - val_accuracy: 0.7000\n",
      "Epoch 16/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8757 - accuracy: 0.7058\n",
      "Epoch 16: val_accuracy improved from 0.70000 to 0.70750, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 14ms/step\n",
      "val_F1_score:  0.7075\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.8757 - accuracy: 0.7058 - val_loss: 0.8895 - val_accuracy: 0.7075\n",
      "Epoch 17/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.7133\n",
      "Epoch 17: val_accuracy did not improve from 0.70750\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.6975\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.8439 - accuracy: 0.7133 - val_loss: 0.8609 - val_accuracy: 0.6975\n",
      "Epoch 18/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.7194\n",
      "Epoch 18: val_accuracy improved from 0.70750 to 0.75250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7525\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.8254 - accuracy: 0.7194 - val_loss: 0.8011 - val_accuracy: 0.7525\n",
      "Epoch 19/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8098 - accuracy: 0.7255\n",
      "Epoch 19: val_accuracy did not improve from 0.75250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.8098 - accuracy: 0.7255 - val_loss: 0.8454 - val_accuracy: 0.7300\n",
      "Epoch 20/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7860 - accuracy: 0.7292\n",
      "Epoch 20: val_accuracy did not improve from 0.75250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.735\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.7860 - accuracy: 0.7292 - val_loss: 0.8294 - val_accuracy: 0.7350\n",
      "Epoch 21/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7753 - accuracy: 0.7320\n",
      "Epoch 21: val_accuracy did not improve from 0.75250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7175\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.7753 - accuracy: 0.7320 - val_loss: 0.8245 - val_accuracy: 0.7175\n",
      "Epoch 22/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7571 - accuracy: 0.7417\n",
      "Epoch 22: val_accuracy did not improve from 0.75250\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7425\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.7571 - accuracy: 0.7417 - val_loss: 0.7492 - val_accuracy: 0.7425\n",
      "Epoch 23/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.7449\n",
      "Epoch 23: val_accuracy did not improve from 0.75250\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7425\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.7366 - accuracy: 0.7449 - val_loss: 0.7685 - val_accuracy: 0.7425\n",
      "Epoch 24/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7325 - accuracy: 0.7455\n",
      "Epoch 24: val_accuracy improved from 0.75250 to 0.76250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 12ms/step\n",
      "val_F1_score:  0.7625\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.7325 - accuracy: 0.7455 - val_loss: 0.7902 - val_accuracy: 0.7625\n",
      "Epoch 25/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.7547\n",
      "Epoch 25: val_accuracy did not improve from 0.76250\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7575\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.7123 - accuracy: 0.7547 - val_loss: 0.7854 - val_accuracy: 0.7575\n",
      "Epoch 26/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.7549\n",
      "Epoch 26: val_accuracy did not improve from 0.76250\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.7525\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.7066 - accuracy: 0.7549 - val_loss: 0.7235 - val_accuracy: 0.7525\n",
      "Epoch 27/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.7648\n",
      "Epoch 27: val_accuracy improved from 0.76250 to 0.77000, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.6808 - accuracy: 0.7648 - val_loss: 0.7503 - val_accuracy: 0.7700\n",
      "Epoch 28/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.7694\n",
      "Epoch 28: val_accuracy did not improve from 0.77000\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.765\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.6670 - accuracy: 0.7694 - val_loss: 0.7423 - val_accuracy: 0.7650\n",
      "Epoch 29/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.7745\n",
      "Epoch 29: val_accuracy did not improve from 0.77000\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.7625\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.6508 - accuracy: 0.7745 - val_loss: 0.7426 - val_accuracy: 0.7625\n",
      "Epoch 30/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.7768\n",
      "Epoch 30: val_accuracy did not improve from 0.77000\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7299999999999999\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.6422 - accuracy: 0.7768 - val_loss: 0.7721 - val_accuracy: 0.7300\n",
      "Epoch 31/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.7747\n",
      "Epoch 31: val_accuracy improved from 0.77000 to 0.79750, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "val_F1_score:  0.7975\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.6337 - accuracy: 0.7747 - val_loss: 0.6683 - val_accuracy: 0.7975\n",
      "Epoch 32/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.7775\n",
      "Epoch 32: val_accuracy did not improve from 0.79750\n",
      "13/13 [==============================] - 0s 17ms/step\n",
      "val_F1_score:  0.7699999999999999\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.6309 - accuracy: 0.7775 - val_loss: 0.7114 - val_accuracy: 0.7700\n",
      "Epoch 33/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.7856\n",
      "Epoch 33: val_accuracy did not improve from 0.79750\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.7725000000000001\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.6157 - accuracy: 0.7856 - val_loss: 0.6664 - val_accuracy: 0.7725\n",
      "Epoch 34/3000\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.7961\n",
      "Epoch 34: val_accuracy improved from 0.79750 to 0.80250, saving model to ./model4/best_model_4.h5\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "val_F1_score:  0.8025\n",
      "\n",
      "Reached 0.80% val_F1_score, so stopping training!!\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.5931 - accuracy: 0.7961 - val_loss: 0.6308 - val_accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f303441d990>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "\n",
    "model4.fit([X_train_spectrogram],y_train_augmented, batch_size=64, epochs=3000, \n",
    "           validation_data=([X_test_spectrogram], y_test_int), callbacks=[callbacks4, metrics, tensorboard4],\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>At end of 34 epoch val_F1_score 0.80</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdef796740ea71c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdef796740ea71c3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model4/model4_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f28208ffa60>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation iou_score values\n",
    "import matplotlib.pyplot as plt\n",
    "his = pd.read_csv('model4/history.csv')\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['loss'])\n",
    "plt.plot(his['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b> From the above plot we can ensure that model is not getting overfit</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
